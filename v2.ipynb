{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b36fab9-1110-4771-b385-d91e65b00b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"Agg\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Flatten)\n",
    "from tensorflow.keras.layers import (Dense, Lambda, Dropout, Activation)\n",
    "from keras.applications.resnet import preprocess_input\n",
    "\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D)\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelBinarizer, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d245f-6357-4921-81e4-a2ac5acbfff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31c03d37-9353-474c-aced-2426a5c24cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "styles_df = pd.read_csv(\"styles.csv\", on_bad_lines='skip')\n",
    "\n",
    "STYLES_CSV_PATH = \"styles.csv\"\n",
    "IMAGES_PATH = \"images\"\n",
    "\n",
    "# print(styles_df.shape)\n",
    "# print(styles_df.head())\n",
    "# print(styles_df.isnull().sum())\n",
    "# for column in styles_df.columns:\n",
    "#     print(f\"Unique values in '{column}':\")\n",
    "#     print(styles_df[column].value_counts())\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bb64a5f-83f3-42bc-a798-2d3e4e9cd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "styles_df = styles_df.dropna()\n",
    "\n",
    "columns_to_drop = ['year', 'productDisplayName', 'masterCategory', 'articleType']\n",
    "existing_columns = [col for col in columns_to_drop if col in styles_df.columns]\n",
    "\n",
    "styles_df.drop(columns=existing_columns, inplace=True)\n",
    "\n",
    "styles_df = styles_df[styles_df['id'].isin([int(i.split('.')[0]) for i in os.listdir(IMAGES_PATH)])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d47e4ab8-c393-4e1f-a89c-284d081cbb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44072, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender subCategory baseColour  season   usage\n",
       "0  15970    Men     Topwear  Navy Blue    Fall  Casual\n",
       "1  39386    Men  Bottomwear       Blue  Summer  Casual\n",
       "2  59263  Women     Watches     Silver  Winter  Casual\n",
       "3  21379    Men  Bottomwear      Black    Fall  Casual\n",
       "4  53759    Men     Topwear       Grey  Summer  Casual"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(styles_df.shape)\n",
    "styles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f48db-fa21-4ad3-8269-35dd62ba0c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09ef0521-7dd6-43a2-9dd2-29c5b5fb24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in styles_df.columns:\n",
    "#     print(f\"Unique values in '{column}':\")\n",
    "#     print(styles_df[column].value_counts())\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d7ba1a-b5e4-496d-a41a-d17264b9a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# output_dir = \"abc\"  # Set your output directory here\n",
    "\n",
    "# for column in styles_df.columns:\n",
    "#     if column == 'id':\n",
    "#         continue\n",
    "\n",
    "#     # Create a new figure for each plot\n",
    "#     plt.figure(figsize=(10, 6))  # Adjust size as needed\n",
    "    \n",
    "#     # Create the plot\n",
    "#     ax = sns.countplot(data=styles_df, x=column, \n",
    "#                       order=styles_df[column].value_counts().index)\n",
    "    \n",
    "#     # Formatting\n",
    "#     plt.title(f'Distribution of {column}', fontsize=14)\n",
    "#     plt.xlabel(column, fontsize=12)\n",
    "#     plt.ylabel('Count', fontsize=12)\n",
    "#     plt.xticks(rotation=45, ha='right')  # Adjust rotation and alignment\n",
    "    \n",
    "#     # Adjust layout to prevent label cutoff\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     # Save in multiple formats (choose what you need)\n",
    "#     filename = f\"distribution_{column.lower().replace(' ', '_')}\"\n",
    "    \n",
    "#     # Save as PDF (vector format)\n",
    "#     plt.savefig(f\"{output_dir}/{filename}.pdf\", \n",
    "#                 bbox_inches='tight', \n",
    "#                 format='pdf')\n",
    "    \n",
    "#     # Save as PNG (high resolution)\n",
    "#     plt.savefig(f\"{output_dir}/{filename}.png\", \n",
    "#                 dpi=300, \n",
    "#                 bbox_inches='tight',\n",
    "#                 transparent=True)\n",
    "    \n",
    "#     # Close the figure to free memory\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d5a0bc7-bc71-4a6f-8e54-f190cd516d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# df=styles_df.copy()\n",
    "# # Assuming you already have your DataFrame as 'df'\n",
    "# attributes = ['gender', 'subCategory', 'baseColour', 'season', 'usage']\n",
    "\n",
    "# for attr in attributes:\n",
    "#     df[attr].value_counts().plot.pie(autopct='%1.1f%%', figsize=(8, 8))\n",
    "#     plt.title(f\"Distribution of {attr}\")\n",
    "#     plt.ylabel(\"\")  \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"{output_dir}/{filename}.png\", \n",
    "#                 dpi=300, \n",
    "#                 bbox_inches='tight',\n",
    "#                 transparent=True)   \n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f099b-78ea-459c-bc28-fd4c9d813363",
   "metadata": {},
   "source": [
    "Unique values in 'gender':\r\n",
    "['Men' 'Women' 'Boys' 'Girls' 'Unisex']\r\n",
    "\r\n",
    "\r\n",
    "Unique values in 'subCategory':\r\n",
    "['Topwear' 'Bottomwear' 'Watches' 'Socks' 'Shoes' 'Belts' 'Flip Flops'\r\n",
    " 'Bags' 'Innerwear' 'Sandal' 'Shoe Accessories' 'Fragrance' 'Jewellery'\r\n",
    " 'Lips' 'Saree' 'Eyewear' 'Scarves' 'Dress' 'Loungewear and Nightwear'\r\n",
    " 'Wallets' 'Apparel Set' 'Headwear' 'Mufflers' 'Skin Care' 'Makeup'\r\n",
    " 'Free Gifts' 'Ties' 'Accessories' 'Nails' 'Beauty Accessories'\r\n",
    " 'Water Bottle' 'Skin' 'Eyes' 'Bath and Body' 'Gloves'\r\n",
    " 'Sports Accessories' 'Cufflinks' 'Sports Equipment' 'Stoles' 'Hair'\r\n",
    " 'Perfumes' 'Home Furnishing' 'Umbrellas' 'Wristbands' 'Vouchers']\r\n",
    "\r\n",
    "\r\n",
    "Unique values in 'baseColour':\r\n",
    "['Navy Blue' 'Blue' 'Silver' 'Black' 'Grey' 'Green' 'Purple' 'White'\r\n",
    " 'Beige' 'Brown' 'Bronze' 'Teal' 'Copper' 'Pink' 'Off White' 'Maroon'\r\n",
    " 'Red' 'Khaki' 'Orange' 'Yellow' 'Charcoal' 'Gold' 'Steel' 'Tan' 'Multi'\r\n",
    " 'Magenta' 'Lavender' 'Sea Green' 'Cream' 'Peach' 'Olive' 'Skin'\r\n",
    " 'Burgundy' 'Coffee Brown' 'Grey Melange' 'Rust' 'Rose' 'Lime Green'\r\n",
    " 'Mauve' 'Turquoise Blue' 'Metallic' 'Mustard' 'Taupe' 'Nude'\r\n",
    " 'Mushroom Brown' 'Fluorescent Green']\r\n",
    "\r\n",
    "\r\n",
    "Unique values in 'season':\r\n",
    "['Fall' 'Summer' 'Winter' 'Spring']\r\n",
    "\r\n",
    "\r\n",
    "Unique values in 'usage':\r\n",
    "['Casual' 'Ethnic' 'Formal' 'Sports' 'Smart Casual' 'Travel' 'Party'\r\n",
    " 'Home']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9e0e23-9f91-4f0c-b028-48ba1258ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_rows = len(styles_df.columns) - 1\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=num_rows, ncols=1, figsize=(15, 5 * num_rows))\n",
    "\n",
    "\n",
    "# axes_index = 0\n",
    "\n",
    "# for column in styles_df.columns:\n",
    "#     if column == 'id':  \n",
    "#         continue\n",
    "\n",
    "#     print(f\"Unique values in '{column}':\")\n",
    "#     print(styles_df[column].unique())\n",
    "#     print(\"\\n\")\n",
    "\n",
    "#     sns.countplot(data=styles_df, x=column, order=styles_df[column].value_counts().index, ax=axes[axes_index])\n",
    "#     axes[axes_index].set_title(f'Distribution of {column}')\n",
    "#     axes[axes_index].set_xticklabels(axes[axes_index].get_xticklabels(), rotation=45)  # Rotate x labels if needed\n",
    "#     axes[axes_index].set_ylabel('Count')\n",
    "\n",
    "    \n",
    "#     axes_index += 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5a3b49b-c2f9-40b7-8e7a-52fc2e3f4457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15108</th>\n",
       "      <td>55396</td>\n",
       "      <td>Women</td>\n",
       "      <td>Eyes</td>\n",
       "      <td>Black</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15110</th>\n",
       "      <td>24557</td>\n",
       "      <td>Women</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Ethnic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15111</th>\n",
       "      <td>10762</td>\n",
       "      <td>Unisex</td>\n",
       "      <td>Flip Flops</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15112</th>\n",
       "      <td>40012</td>\n",
       "      <td>Men</td>\n",
       "      <td>Eyewear</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15113</th>\n",
       "      <td>59903</td>\n",
       "      <td>Women</td>\n",
       "      <td>Scarves</td>\n",
       "      <td>Peach</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender subCategory baseColour  season   usage\n",
       "0      15970     Men     Topwear  Navy Blue    Fall  Casual\n",
       "1      39386     Men  Bottomwear       Blue  Summer  Casual\n",
       "2      59263   Women     Watches     Silver  Winter  Casual\n",
       "3      21379     Men  Bottomwear      Black    Fall  Casual\n",
       "4      53759     Men     Topwear       Grey  Summer  Casual\n",
       "...      ...     ...         ...        ...     ...     ...\n",
       "15108  55396   Women        Eyes      Black  Spring  Casual\n",
       "15110  24557   Women     Topwear     Yellow    Fall  Ethnic\n",
       "15111  10762  Unisex  Flip Flops     Yellow  Winter  Casual\n",
       "15112  40012     Men     Eyewear      Brown  Winter  Casual\n",
       "15113  59903   Women     Scarves      Peach    Fall  Casual\n",
       "\n",
       "[15000 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = styles_df[:15000].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c145aa95-c588-4af4-a992-2c8035a40030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# image_dir = 'images'\n",
    "# image_filenames = os.listdir(image_dir)\n",
    "# image_filenames = [f for f in image_filenames if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "# num_images = len(image_filenames)\n",
    "# if num_images < 9:\n",
    "#     print(f\"Only {num_images} images found. Selecting all available images.\")\n",
    "#     selected_images = image_filenames  \n",
    "# else:\n",
    "#     selected_images = random.sample(image_filenames, 9)\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for ax, img_filename in zip(axes, selected_images):\n",
    "    \n",
    "#     img_path = os.path.join(image_dir, img_filename)\n",
    "#     img = cv2.imread(img_path)\n",
    "    \n",
    "#     if img is None:\n",
    "#         print(f\"Image {img_filename} could not be loaded.\")\n",
    "#         ax.axis('off')  \n",
    "#         ax.set_title(f\"Failed to load\")\n",
    "#         continue  \n",
    "\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     ax.imshow(img)\n",
    "#     ax.set_title(img_filename)\n",
    "#     ax.axis('off')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57be8ad5-68c1-4517-aeed-f3b0d34bca2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_ids = df.pop('id')\n",
    "image_ids = [f\"images/{str(img_id)}.jpg\" for img_id in image_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "401682e6-303e-490e-8e93-ee7bcce7f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_values(x):\n",
    "    x_vc = df[x].value_counts()\n",
    "    x_other = x_vc[x_vc<50].index\n",
    "    df.loc[df[x].isin(x_other),x] = 'Other'\n",
    "    \n",
    "    \n",
    "for col in df.columns:\n",
    "    bin_values(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05061079-8f03-4d8f-a1ac-217e156ea4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea503b6b-0a13-4750-bdc5-68b449d7427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIMS = (180, 180, 3)\n",
    "\n",
    "def load_image(imagePath):\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = preprocess_input(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc0ccf08-704a-4721-b511-9f633939a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [05:07<00:00, 48.77it/s]\n"
     ]
    }
   ],
   "source": [
    "image_data = []\n",
    "for img_path in tqdm(image_ids[:15000]): \n",
    "    img = load_image(img_path)\n",
    "    if img is not None:\n",
    "        image_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74850152-5c90-432f-b6ee-1d2f5d8ce31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.array(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d14eb57-64ed-4b5f-af6f-82f50330c834",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'category_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 430\u001b[0m\n\u001b[0;32m    418\u001b[0m     eval_results \u001b[38;5;241m=\u001b[39m evaluate_models(\n\u001b[0;32m    419\u001b[0m         model,\n\u001b[0;32m    420\u001b[0m         test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestX\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    421\u001b[0m         test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestY_dict\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    422\u001b[0m         class_names_dict\u001b[38;5;241m=\u001b[39mclass_names_dict\n\u001b[0;32m    423\u001b[0m     )\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m eval_results\n\u001b[0;32m    428\u001b[0m prepared_data \u001b[38;5;241m=\u001b[39m prepare_fashion_data(\n\u001b[0;32m    429\u001b[0m     image_ids[:\u001b[38;5;241m15000\u001b[39m],  \u001b[38;5;66;03m# Your image paths\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m     category_labels,    \u001b[38;5;66;03m# Your category labels\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     color_labels        \u001b[38;5;66;03m# Your color labels\u001b[39;00m\n\u001b[0;32m    432\u001b[0m )\n\u001b[0;32m    434\u001b[0m optimized_results \u001b[38;5;241m=\u001b[39m run_optimized_pipeline(prepared_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'category_labels' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def prepare_fashion_data(image_paths, category_labels, color_labels, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Prepare fashion data for multi-output classification\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_paths : list\n",
    "        List of image file paths\n",
    "    category_labels : list or array\n",
    "        Category labels corresponding to each image\n",
    "    color_labels : list or array\n",
    "        Color labels corresponding to each image\n",
    "    test_size : float\n",
    "        Proportion of data to use for testing\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing processed data and label binarizers\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    print(\"Loading and preprocessing images...\")\n",
    "    image_data = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for idx, img_path in enumerate(tqdm(image_paths)):\n",
    "        img = load_image(img_path)\n",
    "        if img is not None:\n",
    "            image_data.append(img)\n",
    "            valid_indices.append(idx)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    image_data = np.array(image_data)\n",
    "    \n",
    "    # Filter labels to match valid images\n",
    "    category_labels = np.array(category_labels)[valid_indices]\n",
    "    color_labels = np.array(color_labels)[valid_indices]\n",
    "    \n",
    "    # Initialize label binarizers\n",
    "    category_lb = LabelBinarizer()\n",
    "    color_lb = LabelBinarizer()\n",
    "    \n",
    "    # Transform labels\n",
    "    category_onehot = category_lb.fit_transform(category_labels)\n",
    "    color_onehot = color_lb.fit_transform(color_labels)\n",
    "    \n",
    "    # Create class names dictionary\n",
    "    class_names_dict = {\n",
    "        'category': category_lb.classes_.tolist(),\n",
    "        'color': color_lb.classes_.tolist()\n",
    "    }\n",
    "    \n",
    "    # Save class names\n",
    "    import json\n",
    "    with open('fashion_class_names.json', 'w') as f:\n",
    "        json.dump(class_names_dict, f)\n",
    "    \n",
    "    # Split data\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Use category for stratification\n",
    "    for train_idx, test_idx in sss.split(image_data, category_labels):\n",
    "        trainX = image_data[train_idx]\n",
    "        testX = image_data[test_idx]\n",
    "        \n",
    "        train_category = category_onehot[train_idx]\n",
    "        test_category = category_onehot[test_idx]\n",
    "        \n",
    "        train_color = color_onehot[train_idx]\n",
    "        test_color = color_onehot[test_idx]\n",
    "    \n",
    "    # Prepare dictionaries for model training\n",
    "    trainY_dict = {\n",
    "        'category_output': train_category,\n",
    "        'color_output': train_color\n",
    "    }\n",
    "    \n",
    "    testY_dict = {\n",
    "        'category_output': test_category,\n",
    "        'color_output': test_color\n",
    "    }\n",
    "    \n",
    "    # Create label binarizers dictionary\n",
    "    label_binarizers = {\n",
    "        'category': category_lb,\n",
    "        'color': color_lb\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'trainX': trainX,\n",
    "        'trainY_dict': trainY_dict,\n",
    "        'testX': testX,\n",
    "        'testY_dict': testY_dict,\n",
    "        'label_binarizers': label_binarizers,\n",
    "        'class_names_dict': class_names_dict\n",
    "    }\n",
    "    \n",
    "    \n",
    "def create_lightweight_branch(input_layer, num_classes, activation, name):\n",
    "    \"\"\"Create a simplified classification branch\"\"\"\n",
    "    base_name = name.replace('_output', '')\n",
    "    \n",
    "    x = Dense(128, activation='relu', name=f'{name}_dense1')(input_layer)\n",
    "    x = BatchNormalization(name=f'{name}_bn1')(x)\n",
    "    x = Dropout(0.2, name=f'{name}_dropout1')(x)\n",
    "    x = Dense(64, activation='relu', name=f'{name}_dense2')(x)\n",
    "    output = Dense(num_classes, activation=activation, name=f'{name}_output')(x)\n",
    "    return output\n",
    "\n",
    "def build_optimized_model(width, height, num_classes_dict):\n",
    "    \"\"\"Build a lightweight multi-output model\"\"\"\n",
    "    IMAGE_DIMS = (height, width, 3)\n",
    "    \n",
    "    base_model = MobileNetV2(\n",
    "        weights='imagenet', \n",
    "        include_top=False, \n",
    "        input_shape=IMAGE_DIMS,\n",
    "        alpha=0.75  \n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = Input(shape=IMAGE_DIMS, name='input_image')\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D(name='gap')(x)  \n",
    "    \n",
    "    outputs = {}\n",
    "    for task_name, num_classes in num_classes_dict.items():\n",
    "        output_name = f'{task_name}_output'\n",
    "        outputs[output_name] = create_lightweight_branch(\n",
    "            x, \n",
    "            num_classes=num_classes,\n",
    "            activation='softmax',\n",
    "            name=task_name\n",
    "        )\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_optimized_model(trainX, trainY_dict, testX, testY_dict, epochs=40, batch_size=32):\n",
    "    \"\"\"Train the optimized multi-output fashion classification model\"\"\"\n",
    "    print(\"\\nTraining data shapes:\")\n",
    "    for name, labels in trainY_dict.items():\n",
    "        print(f\"{name}: {labels.shape}\")\n",
    "    \n",
    "    num_classes_dict = {\n",
    "        name.replace('_output', ''): labels.shape[1]\n",
    "        for name, labels in trainY_dict.items()\n",
    "    }\n",
    "    \n",
    "    model = build_optimized_model(180, 180, num_classes_dict)\n",
    "    \n",
    "    losses = {name: \"categorical_crossentropy\" for name in trainY_dict.keys()}\n",
    "    metrics = {name: \"accuracy\" for name in trainY_dict.keys()}\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss=losses, metrics=metrics)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(\n",
    "        trainX,\n",
    "        trainY_dict,\n",
    "        validation_data=(testX, testY_dict),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def evaluate_models(model, testX, testY_dict, tflite_model=None, class_names_dict=None):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model and optionally its TFLite version\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : keras.Model\n",
    "        The trained multi-output Keras model\n",
    "    testX : numpy.ndarray\n",
    "        Test images\n",
    "    testY_dict : dict\n",
    "        Dictionary of test labels, with task names as keys and one-hot encoded labels as values\n",
    "    tflite_model : bytes, optional\n",
    "        TFLite model bytes for evaluation\n",
    "    class_names_dict : dict, optional\n",
    "        Dictionary mapping task names to lists of class names for detailed reporting\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Evaluation metrics for each model type and task\n",
    "    \"\"\"\n",
    "    results = {'keras_model': {}, 'tflite_model': {}}\n",
    "    \n",
    "    # Evaluate Keras model\n",
    "    print(\"\\n===== Evaluating Keras Model =====\")\n",
    "    keras_eval = model.evaluate(testX, testY_dict, verbose=1)\n",
    "    \n",
    "    # Extract and format results\n",
    "    loss_idx = 0\n",
    "    for i, task_name in enumerate(testY_dict.keys()):\n",
    "        accuracy_idx = loss_idx + 1\n",
    "        results['keras_model'][task_name] = {\n",
    "            'loss': keras_eval[loss_idx],\n",
    "            'accuracy': keras_eval[accuracy_idx]\n",
    "        }\n",
    "        print(f\"{task_name}: Loss = {keras_eval[loss_idx]:.4f}, Accuracy = {keras_eval[accuracy_idx]:.4f}\")\n",
    "        loss_idx += 2\n",
    "    \n",
    "    # Generate detailed classification metrics\n",
    "    if class_names_dict:\n",
    "        from sklearn.metrics import classification_report, confusion_matrix\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(testX)\n",
    "        \n",
    "        for task_name in testY_dict.keys():\n",
    "            # Convert one-hot encoded predictions and labels back to class indices\n",
    "            pred_indices = np.argmax(predictions[task_name], axis=1)\n",
    "            true_indices = np.argmax(testY_dict[task_name], axis=1)\n",
    "            \n",
    "            # Get class names for this task\n",
    "            task_base_name = task_name.replace('_output', '')\n",
    "            class_names = class_names_dict.get(task_base_name, None)\n",
    "            \n",
    "            print(f\"\\n===== Detailed Metrics for {task_base_name} =====\")\n",
    "            \n",
    "            # Classification report\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(\n",
    "                true_indices, \n",
    "                pred_indices,\n",
    "                target_names=class_names if class_names else None\n",
    "            ))\n",
    "            \n",
    "            # Confusion matrix\n",
    "            cm = confusion_matrix(true_indices, pred_indices)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(\n",
    "                cm, \n",
    "                annot=True, \n",
    "                fmt=\"d\", \n",
    "                cmap=\"Blues\",\n",
    "                xticklabels=class_names if class_names else \"auto\",\n",
    "                yticklabels=class_names if class_names else \"auto\"\n",
    "            )\n",
    "            plt.title(f'Confusion Matrix for {task_base_name}')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'confusion_matrix_{task_base_name}.png')\n",
    "            plt.close()\n",
    "    \n",
    "    # Evaluate TFLite model if provided\n",
    "    if tflite_model is not None:\n",
    "        print(\"\\n===== Evaluating TFLite Model =====\")\n",
    "        \n",
    "        # Create TFLite interpreter\n",
    "        interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "        interpreter.allocate_tensors()\n",
    "        \n",
    "        # Get input and output details\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        \n",
    "        # Prepare for accuracy calculation\n",
    "        task_correct_predictions = {task: 0 for task in testY_dict.keys()}\n",
    "        total_samples = testX.shape[0]\n",
    "        \n",
    "        # Process batch by batch to avoid memory issues\n",
    "        batch_size = 32\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            batch_end = min(i + batch_size, total_samples)\n",
    "            batch_x = testX[i:batch_end]\n",
    "            \n",
    "            # Process each sample in the batch\n",
    "            for j in range(batch_x.shape[0]):\n",
    "                sample = batch_x[j:j+1].astype(np.float32)\n",
    "                \n",
    "                # Set input tensor\n",
    "                interpreter.set_tensor(input_details[0]['index'], sample)\n",
    "                \n",
    "                # Run inference\n",
    "                interpreter.invoke()\n",
    "                \n",
    "                # Get outputs\n",
    "                for k, details in enumerate(output_details):\n",
    "                    task_name = list(testY_dict.keys())[k]\n",
    "                    task_base_name = task_name.replace('_output', '')\n",
    "                    \n",
    "                    output_data = interpreter.get_tensor(details['index'])\n",
    "                    pred_class = np.argmax(output_data[0])\n",
    "                    true_class = np.argmax(testY_dict[task_name][i+j])\n",
    "                    \n",
    "                    if pred_class == true_class:\n",
    "                        task_correct_predictions[task_name] += 1\n",
    "        \n",
    "        # Calculate and display accuracies\n",
    "        for task_name in testY_dict.keys():\n",
    "            accuracy = task_correct_predictions[task_name] / total_samples\n",
    "            results['tflite_model'][task_name] = {'accuracy': accuracy}\n",
    "            print(f\"{task_name}: TFLite Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def convert_to_tflite(model, quantize=True):\n",
    "    \"\"\"Convert model to TFLite format with optional quantization\"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    if quantize:\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # Print size information\n",
    "    print(f\"TFLite model size: {len(tflite_model) / (1024 * 1024):.2f} MB\")\n",
    "    \n",
    "    return tflite_model\n",
    "\n",
    "def run_optimized_pipeline(\n",
    "    data_prep_results,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    verbose=True):\n",
    "    \"\"\"Run the optimized model training pipeline using previously prepared data\"\"\"\n",
    "    trainX = data_prep_results['trainX']\n",
    "    trainY_dict = data_prep_results['trainY_dict']\n",
    "    testX = data_prep_results['testX']\n",
    "    testY_dict = data_prep_results['testY_dict']\n",
    "    class_names_dict = data_prep_results.get('class_names_dict', None)\n",
    "    \n",
    "    print(\"\\nStarting optimized model training...\")\n",
    "    model, history = train_optimized_model(\n",
    "        trainX,\n",
    "        trainY_dict,\n",
    "        testX,\n",
    "        testY_dict,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    # Convert to TFLite\n",
    "    tflite_model = convert_to_tflite(model, quantize=True)\n",
    "    \n",
    "    # Save TFLite model\n",
    "    with open('fashion_classifier_optimized.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    # Save regular model with optimization\n",
    "    model.save('fashion_classifier_optimized.h5', save_format='h5')\n",
    "    \n",
    "    # Try to save in TensorFlow SavedModel format which is more efficient\n",
    "    model.save('fashion_classifier_optimized', save_format='tf')\n",
    "    \n",
    "    # Run evaluation\n",
    "    print(\"\\nEvaluating models...\")\n",
    "    eval_results = evaluate_models(\n",
    "        model, \n",
    "        testX, \n",
    "        testY_dict, \n",
    "        tflite_model=tflite_model,\n",
    "        class_names_dict=class_names_dict\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'tflite_model': tflite_model,\n",
    "        'history': history,\n",
    "        'evaluation': eval_results,\n",
    "        'class_names_dict': class_names_dict\n",
    "    }\n",
    "\n",
    "def load_class_names():\n",
    "    \"\"\"Load previously saved class names dictionary\"\"\"\n",
    "    import json\n",
    "    try:\n",
    "        with open('class_names.json', 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Class names file not found. Returning empty dictionary.\")\n",
    "        return {}\n",
    "\n",
    "# Example of how to load and use the class names for evaluation later\n",
    "def evaluate_saved_model(model_path='fashion_classifier_optimized.h5', test_data=None):\n",
    "    \"\"\"Evaluate a previously saved model\"\"\"\n",
    "    from tensorflow.keras.models import load_model\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Load class names\n",
    "    class_names_dict = load_class_names()\n",
    "    \n",
    "    # Load test data if not provided\n",
    "    if test_data is None:\n",
    "        # You'd need logic here to load your test data\n",
    "        pass\n",
    "    \n",
    "    # Run evaluation\n",
    "    eval_results = evaluate_models(\n",
    "        model,\n",
    "        test_data['testX'],\n",
    "        test_data['testY_dict'],\n",
    "        class_names_dict=class_names_dict\n",
    "    )\n",
    "    \n",
    "    return eval_results\n",
    "\n",
    "\n",
    "prepared_data = prepare_fashion_data(\n",
    "    image_ids[:15000],  # Your image paths\n",
    "    category_labels,    # Your category labels\n",
    "    color_labels        # Your color labels\n",
    ")\n",
    "\n",
    "optimized_results = run_optimized_pipeline(prepared_data, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69960688-bc78-4673-9ba7-0546cade1b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4715c-4ee3-4df9-8043-c6c738ddd909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727834c1-70a1-45c9-a57a-f36482e60a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6e157-6c02-414c-a3dc-089c5f71e7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70988b66-d2f2-4223-8f09-2aad79ede5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2145007-79b9-4172-9145-d32f39d44127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4a722-33b4-48ca-8277-862ad2f80d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69d2d8f-0e10-43b0-8d45-cf6780368bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, testX, testY_dict):\n",
    "#     print(\"\\nEvaluating the model on test data...\")\n",
    "#     print(f\"testX shape: {testX.shape}\")\n",
    "    \n",
    "#     # Show output shapes for debugging\n",
    "#     for name, y in testY_dict.items():\n",
    "#         print(f\"{name} shape: {y.shape}\")\n",
    "    \n",
    "#     # Get predictions\n",
    "#     print(\"\\nGenerating predictions...\")\n",
    "#     predictions = model.predict(testX, verbose=1)\n",
    "    \n",
    "#     # Calculate metrics manually\n",
    "#     results = {}\n",
    "#     print(\"\\nIndividual Output Accuracies:\")\n",
    "#     for output_name in model.output_names:\n",
    "#         if output_name in predictions and output_name in testY_dict:\n",
    "#             y_true = testY_dict[output_name]\n",
    "#             y_pred = predictions[output_name]\n",
    "            \n",
    "#             # Calculate categorical accuracy\n",
    "#             accuracy = np.mean(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
    "#             results[f\"{output_name}_accuracy\"] = accuracy\n",
    "#             print(f\"{output_name} accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "#             # Calculate top-3 accuracy for categories with many classes\n",
    "#             if y_true.shape[1] > 10:  # For outputs with many classes\n",
    "#                 top3_accuracy = calculate_top_k_accuracy(y_true, y_pred, k=3)\n",
    "#                 results[f\"{output_name}_top3_accuracy\"] = top3_accuracy\n",
    "#                 print(f\"{output_name} top-3 accuracy: {top3_accuracy:.4f}\")\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# def calculate_top_k_accuracy(y_true, y_pred, k=3):\n",
    "#     \"\"\"Calculate top-k accuracy for multi-class classification\"\"\"\n",
    "#     true_classes = np.argmax(y_true, axis=1)\n",
    "#     pred_classes = np.argsort(y_pred, axis=1)[:, -k:]  # Get top k predictions\n",
    "    \n",
    "#     # Check if true class is in top k predictions for each sample\n",
    "#     correct = 0\n",
    "#     for i, true_class in enumerate(true_classes):\n",
    "#         if true_class in pred_classes[i]:\n",
    "#             correct += 1\n",
    "    \n",
    "#     return correct / len(true_classes)\n",
    "# evaluate_model(model, testX, testY_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b5d9a4-f3b8-47cf-92d6-09fa36987ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, testX, testY_dict, label_binarizers=None, num_classes_dict=None):\n",
    "#     print(\"\\nEvaluating the model on test data...\")\n",
    "#     print(f\"testX shape: {testX.shape}\")\n",
    "    \n",
    "#     # Import necessary libraries if not already imported\n",
    "#     from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "#     # Show output shapes for debugging\n",
    "#     for name, y in testY_dict.items():\n",
    "#         print(f\"{name} shape: {y.shape}\")\n",
    "    \n",
    "#     # Get predictions\n",
    "#     print(\"\\nGenerating predictions...\")\n",
    "#     predictions = model.predict(testX, verbose=1)\n",
    "    \n",
    "#     # Calculate metrics manually\n",
    "#     results = {}\n",
    "#     print(\"\\nPerformance Metrics:\")\n",
    "    \n",
    "#     for output_name in model.output_names:\n",
    "#         if output_name in predictions and output_name in testY_dict:\n",
    "#             print(f\"\\n----- {output_name} Metrics -----\")\n",
    "#             y_true = testY_dict[output_name]\n",
    "#             y_pred = predictions[output_name]\n",
    "            \n",
    "#             # Get the attribute name without the \"_output\" suffix\n",
    "#             attr_name = output_name.replace('_output', '')\n",
    "            \n",
    "#             # Convert to class indices\n",
    "#             y_true_classes = np.argmax(y_true, axis=1)\n",
    "#             y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "            \n",
    "#             # Get class names if label_binarizers is available\n",
    "#             class_names = None\n",
    "#             if label_binarizers and attr_name in label_binarizers:\n",
    "#                 try:\n",
    "#                     class_names = label_binarizers[attr_name].classes_\n",
    "#                     print(f\"\\nClass mapping for {attr_name}:\")\n",
    "#                     for idx, name in enumerate(class_names):\n",
    "#                         print(f\"Class {idx}: {name}\")\n",
    "#                 except AttributeError:\n",
    "#                     print(f\"Warning: Could not access classes_ attribute in label_binarizer for {attr_name}\")\n",
    "#                     class_names = None\n",
    "            \n",
    "#             # Calculate accuracy\n",
    "#             accuracy = np.mean(y_true_classes == y_pred_classes)\n",
    "#             results[f\"{output_name}_accuracy\"] = accuracy\n",
    "#             print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "#             # Calculate top-3 accuracy for categories with many classes\n",
    "#             if y_true.shape[1] > 10:  # For outputs with many classes\n",
    "#                 top3_accuracy = calculate_top_k_accuracy(y_true, y_pred, k=3)\n",
    "#                 results[f\"{output_name}_top3_accuracy\"] = top3_accuracy\n",
    "#                 print(f\"Top-3 Accuracy: {top3_accuracy:.4f}\")\n",
    "            \n",
    "#             # Calculate precision, recall, and F1 (macro-averaged)\n",
    "#             precision = precision_score(y_true_classes, y_pred_classes, average='macro', zero_division=0)\n",
    "#             recall = recall_score(y_true_classes, y_pred_classes, average='macro', zero_division=0)\n",
    "#             f1 = f1_score(y_true_classes, y_pred_classes, average='macro', zero_division=0)\n",
    "            \n",
    "#             results[f\"{output_name}_precision\"] = precision\n",
    "#             results[f\"{output_name}_recall\"] = recall\n",
    "#             results[f\"{output_name}_f1\"] = f1\n",
    "            \n",
    "#             print(f\"Precision (macro): {precision:.4f}\")\n",
    "#             print(f\"Recall (macro): {recall:.4f}\")\n",
    "#             print(f\"F1 Score (macro): {f1:.4f}\")\n",
    "            \n",
    "#             # Calculate class-wise metrics for detailed analysis\n",
    "#             class_precision = precision_score(y_true_classes, y_pred_classes, average=None, zero_division=0)\n",
    "#             class_recall = recall_score(y_true_classes, y_pred_classes, average=None, zero_division=0)\n",
    "#             class_f1 = f1_score(y_true_classes, y_pred_classes, average=None, zero_division=0)\n",
    "            \n",
    "#             # Find top and bottom performing classes\n",
    "#             top_classes_idx = np.argsort(class_f1)[-3:][::-1]  # Top 3 classes by F1\n",
    "#             bottom_classes_idx = np.argsort(class_f1)[:3]      # Bottom 3 classes by F1\n",
    "            \n",
    "#             print(\"\\nTop 3 Classes by F1 Score:\")\n",
    "#             for idx in top_classes_idx:\n",
    "#                 if class_names is not None and idx < len(class_names):\n",
    "#                     class_label = class_names[idx]\n",
    "#                 else:\n",
    "#                     class_label = f\"Class {idx}\"\n",
    "#                 print(f\"{class_label}: F1={class_f1[idx]:.4f}, Precision={class_precision[idx]:.4f}, Recall={class_recall[idx]:.4f}\")\n",
    "            \n",
    "#             print(\"\\nBottom 3 Classes by F1 Score:\")\n",
    "#             for idx in bottom_classes_idx:\n",
    "#                 if class_names is not None and idx < len(class_names):\n",
    "#                     class_label = class_names[idx]\n",
    "#                 else:\n",
    "#                     class_label = f\"Class {idx}\"\n",
    "#                 print(f\"{class_label}: F1={class_f1[idx]:.4f}, Precision={class_precision[idx]:.4f}, Recall={class_recall[idx]:.4f}\")\n",
    "            \n",
    "#             # Generate confusion matrix\n",
    "#             cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "            \n",
    "#             # If there are many classes, calculate a simplified confusion matrix\n",
    "#             # showing just the most confused pairs\n",
    "#             if y_true.shape[1] > 10:\n",
    "#                 print(\"\\nTop Misclassifications:\")\n",
    "#                 # Find pairs with high misclassification rates\n",
    "#                 np.fill_diagonal(cm, 0)  # Ignore the diagonal (correct predictions)\n",
    "#                 if np.sum(cm) > 0:  # Only proceed if there are misclassifications\n",
    "#                     total_misclassified = np.sum(cm)\n",
    "                    \n",
    "#                     # Get top 5 misclassification pairs\n",
    "#                     flat_indices = np.argsort(cm.flatten())[-5:]\n",
    "#                     for idx in flat_indices:\n",
    "#                         true_class = idx // cm.shape[1]\n",
    "#                         pred_class = idx % cm.shape[1]\n",
    "                        \n",
    "#                         # Check bounds for class names\n",
    "#                         if class_names is not None:\n",
    "#                             true_name = class_names[true_class] if true_class < len(class_names) else f\"Class {true_class}\"\n",
    "#                             pred_name = class_names[pred_class] if pred_class < len(class_names) else f\"Class {pred_class}\"\n",
    "#                         else:\n",
    "#                             true_name = f\"Class {true_class}\"\n",
    "#                             pred_name = f\"Class {pred_class}\"\n",
    "                        \n",
    "#                         misclass_rate = cm[true_class, pred_class] / total_misclassified\n",
    "#                         print(f\"True: {true_name} → Predicted: {pred_name}: {cm[true_class, pred_class]} instances ({misclass_rate:.1%} of all errors)\")\n",
    "#                 else:\n",
    "#                     print(\"No misclassifications found (perfect predictions on test set)\")\n",
    "            \n",
    "#             # Store confusion matrix and class names\n",
    "#             results[f\"{output_name}_confusion_matrix\"] = cm\n",
    "#             if class_names is not None:\n",
    "#                 results[f\"{output_name}_class_names\"] = class_names\n",
    "            \n",
    "#     return results\n",
    "# def calculate_top_k_accuracy(y_true, y_pred, k=3):\n",
    "#     \"\"\"Calculate top-k accuracy for multi-class classification\"\"\"\n",
    "#     true_classes = np.argmax(y_true, axis=1)\n",
    "#     pred_classes = np.argsort(y_pred, axis=1)[:, -k:]  # Get top k predictions\n",
    "    \n",
    "#     # Check if true class is in top k predictions for each sample\n",
    "#     correct = 0\n",
    "#     for i, true_class in enumerate(true_classes):\n",
    "#         if true_class in pred_classes[i]:\n",
    "#             correct += 1\n",
    "    \n",
    "#     return correct / len(true_classes)\n",
    "\n",
    "# def plot_confusion_matrix(cm, class_names=None, figsize=(10, 8), title='Confusion Matrix'):\n",
    "#     \"\"\"Plot a confusion matrix with better visualization for many classes\"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn as sns\n",
    "#     import numpy as np\n",
    "    \n",
    "#     # If there are many classes, plot a heatmap only\n",
    "#     if cm.shape[0] > 10:\n",
    "#         plt.figure(figsize=figsize)\n",
    "#         # Use logarithmic scale for better visualization when classes are imbalanced\n",
    "#         sns.heatmap(cm, cmap='Blues', norm=LogNorm(vmin=0.1, vmax=cm.max()))\n",
    "#         plt.title(title)\n",
    "#         plt.ylabel('True Label')\n",
    "#         plt.xlabel('Predicted Label')\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         # For fewer classes, we can show actual numbers and class names\n",
    "#         plt.figure(figsize=figsize)\n",
    "        \n",
    "#         if class_names is None:\n",
    "#             class_names = [str(i) for i in range(cm.shape[0])]\n",
    "            \n",
    "#         # Calculate percentages (normalize by row)\n",
    "#         cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "#         # Create a custom annotation function to show counts and percentages\n",
    "#         annot = np.empty_like(cm, dtype=object)\n",
    "#         for i in range(cm.shape[0]):\n",
    "#             for j in range(cm.shape[1]):\n",
    "#                 annot[i, j] = f\"{cm[i, j]}\\n({cm_normalized[i, j]:.1%})\"\n",
    "        \n",
    "#         sns.heatmap(cm, annot=annot, fmt=\"\", cmap=\"Blues\", \n",
    "#                     xticklabels=class_names, \n",
    "#                     yticklabels=class_names)\n",
    "#         plt.ylabel('True Label')\n",
    "#         plt.xlabel('Predicted Label')\n",
    "#         plt.title(title)\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "# def plot_and_save_confusion_matrices(results, output_dir='confusion_matrices', figsize=(12, 10)):\n",
    "#     \"\"\"\n",
    "#     Plot and save confusion matrices for all outputs\n",
    "    \n",
    "#     Parameters:\n",
    "#     results: Dictionary containing evaluation results with confusion matrices\n",
    "#     output_dir: Directory to save the plots (will be created if it doesn't exist)\n",
    "#     figsize: Size of the figure for each confusion matrix\n",
    "#     \"\"\"\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import seaborn as sns\n",
    "#     import numpy as np\n",
    "#     import os\n",
    "#     from matplotlib.colors import LogNorm\n",
    "    \n",
    "#     # Create output directory if it doesn't exist\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "#     # Find all confusion matrices in results\n",
    "#     for key in results:\n",
    "#         if key.endswith('_confusion_matrix'):\n",
    "#             output_name = key.replace('_confusion_matrix', '')\n",
    "#             cm = results[key]\n",
    "            \n",
    "#             # Get class names if available\n",
    "#             class_names = None\n",
    "#             if f\"{output_name}_class_names\" in results:\n",
    "#                 class_names = results[f\"{output_name}_class_names\"]\n",
    "            \n",
    "#             # Create figure\n",
    "#             plt.figure(figsize=figsize)\n",
    "            \n",
    "#             # Decide on visualization approach based on number of classes\n",
    "#             if cm.shape[0] > 10:\n",
    "#                 # For many classes, use a heatmap without annotations\n",
    "#                 sns.heatmap(cm, cmap='Blues', norm=LogNorm(vmin=0.1, vmax=cm.max()))\n",
    "#                 plt.title(f\"{output_name} Confusion Matrix\")\n",
    "#                 plt.ylabel('True Label')\n",
    "#                 plt.xlabel('Predicted Label')\n",
    "#             else:\n",
    "#                 # For fewer classes, show counts and percentages\n",
    "#                 # Calculate percentages (normalize by row)\n",
    "#                 cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                \n",
    "#                 # Create a custom annotation function to show counts and percentages\n",
    "#                 annot = np.empty_like(cm, dtype=object)\n",
    "#                 for i in range(cm.shape[0]):\n",
    "#                     for j in range(cm.shape[1]):\n",
    "#                         annot[i, j] = f\"{cm[i, j]}\\n({cm_normalized[i, j]:.1%})\"\n",
    "                \n",
    "#                 # Get tick labels\n",
    "#                 if class_names is not None:\n",
    "#                     xticklabels = class_names\n",
    "#                     yticklabels = class_names\n",
    "#                 else:\n",
    "#                     xticklabels = list(range(cm.shape[1]))\n",
    "#                     yticklabels = list(range(cm.shape[0]))\n",
    "                \n",
    "#                 sns.heatmap(cm, annot=annot, fmt=\"\", cmap=\"Blues\", \n",
    "#                            xticklabels=xticklabels, \n",
    "#                            yticklabels=yticklabels)\n",
    "#                 plt.ylabel('True Label')\n",
    "#                 plt.xlabel('Predicted Label')\n",
    "#                 plt.title(f\"{output_name} Confusion Matrix\")\n",
    "            \n",
    "#             plt.tight_layout()\n",
    "            \n",
    "#             # Save the figure\n",
    "#             filename = os.path.join(output_dir, f\"{output_name}_confusion_matrix.png\")\n",
    "#             plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "#             print(f\"Saved {filename}\")\n",
    "            \n",
    "#             # Close the figure to free memory\n",
    "#             plt.close()\n",
    "            \n",
    "#     print(f\"All confusion matrices saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c2df28-8621-46f3-a97b-b6142aecaf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_and_save_confusion_matrices(results, output_dir='model_evaluation/confusion_matrices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5b2177-c715-4c77-aa40-867aa6266ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = evaluate_model(\n",
    "#     model, \n",
    "#     testX, \n",
    "#     testY_dict,\n",
    "#     label_binarizers=label_binarizers,\n",
    "#     num_classes_dict=num_classes_dict\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560fd3a-c271-4b71-954d-99a2a638415a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d44ec-57ef-4e7e-bd72-d1efe8fff14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2f585-f678-402c-9028-16effef01a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752c10c-2993-4894-a302-beae1ee52729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c345acc-5bca-46e2-a723-d1a4f16abede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4d8c4de-c19a-4438-9293-19857ecdc6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = advanced_data_preparation(image_data, df, sample_size=13200, test_size=0.2, random_state=42, z_threshold=3)\n",
    "# testX = data['testX']\n",
    "# testY_dict = data['testY_dict']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0a68ff-770d-48a3-a407-8b14be801b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, testX, testY_dict):\n",
    "#     print(\"\\nEvaluating the model on test data...\")\n",
    "#     print(f\"testX shape: {testX.shape}\")\n",
    "\n",
    "#     ordered_testY = []\n",
    "#     for name in model.output_names:\n",
    "#         y = testY_dict.get(name)\n",
    "#         if y is None:\n",
    "#             raise ValueError(f\"Missing output: {name} in testY_dict\")\n",
    "#         print(f\"{name} shape: {y.shape}\")\n",
    "#         ordered_testY.append(y)\n",
    "\n",
    "#     # Now evaluate\n",
    "#     results = model.evaluate(testX, ordered_testY, verbose=1)\n",
    "#     metric_names = model.metrics_names\n",
    "\n",
    "#     print(\"\\nEvaluation Metrics:\")\n",
    "#     for name, value in zip(metric_names, results):\n",
    "#         print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "#     return dict(zip(metric_names, results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "399ae110-f7c0-47fd-a3e4-c3c2e979506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelBinarizer, RobustScaler\n",
    "from scipy import stats\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def advanced_data_preparation(\n",
    "    image_data, \n",
    "    df, \n",
    "    sample_size=None, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    z_threshold=3,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Comprehensive data preparation function with:\n",
    "    - Sampling \n",
    "    - Outlier removal\n",
    "    - Label binarization\n",
    "    - Stratified splitting\n",
    "    \"\"\"\n",
    "    if sample_size is None:\n",
    "        sample_size = len(df)\n",
    "    \n",
    "    image_data_sampled = image_data[:sample_size]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nOriginal DataFrame columns:\", df.columns)\n",
    "        for column in ['subCategory', 'gender', 'baseColour', 'season', 'usage']:\n",
    "            unique_values = df[column].nunique()\n",
    "            print(f\"\\nUnique values in {column}: {unique_values}\")\n",
    "            print(f\"Values: {sorted(df[column].unique())}\")\n",
    "    \n",
    "    \n",
    "    label_mapping = {\n",
    "        'subCategory': 'subCategory',\n",
    "        'gender': 'gender',\n",
    "        'baseColour': 'color',\n",
    "        'season': 'season',\n",
    "        'usage': 'usage'\n",
    "    }\n",
    "    \n",
    "    label_binarizers = {\n",
    "        output_name: LabelBinarizer()\n",
    "        for output_name in label_mapping.values()\n",
    "    }\n",
    "    \n",
    "    labels_dict = {}\n",
    "    for input_name, output_name in label_mapping.items():\n",
    "        labels_dict[f'{output_name}_output'] = label_binarizers[output_name].fit_transform(\n",
    "            np.array(df[input_name].values[:sample_size])\n",
    "        )\n",
    "    \n",
    "    def remove_outliers(data, labels_dict, z_threshold=3):\n",
    "        \"\"\"Remove outliers using z-score method across multiple labels\"\"\"\n",
    "        total_samples = len(data)\n",
    "        keep_mask = np.ones(total_samples, dtype=bool)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nInitial Shapes:\")\n",
    "            print(f\"Data shape: {data.shape}\")\n",
    "            for name, labels in labels_dict.items():\n",
    "                print(f\"{name} shape: {labels.shape}\")\n",
    "        \n",
    "        for label_name, labels in labels_dict.items():\n",
    "            if verbose:\n",
    "                print(f\"\\nProcessing {label_name}:\")\n",
    "                print(f\"Initial samples: {np.sum(keep_mask)}\")\n",
    "            \n",
    "            label_indices = np.argmax(labels, axis=1)\n",
    "            z_scores = np.abs(stats.zscore(label_indices))\n",
    "            current_mask = z_scores < z_threshold\n",
    "            keep_mask = keep_mask & current_mask\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Samples after filtering: {np.sum(keep_mask)}\")\n",
    "        \n",
    "        clean_data = data[keep_mask]\n",
    "        clean_labels_dict = {\n",
    "            key: labels[keep_mask] for key, labels in labels_dict.items()\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nAfter removing outliers:\")\n",
    "            print(f\"Clean data shape: {clean_data.shape}\")\n",
    "            for name, labels in clean_labels_dict.items():\n",
    "                print(f\"{name} shape: {labels.shape}\")\n",
    "        \n",
    "        return clean_data, clean_labels_dict\n",
    "    \n",
    "    clean_data, clean_labels_dict = remove_outliers(\n",
    "        image_data_sampled, \n",
    "        labels_dict, \n",
    "        z_threshold=z_threshold\n",
    "    )\n",
    "    \n",
    "    stratified_split = StratifiedShuffleSplit(\n",
    "        n_splits=1, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    primary_label = clean_labels_dict['subCategory_output']\n",
    "    primary_label_indices = np.argmax(primary_label, axis=1)\n",
    "    \n",
    "    for train_index, test_index in stratified_split.split(clean_data, primary_label_indices):\n",
    "        trainX = clean_data[train_index]\n",
    "        testX = clean_data[test_index]\n",
    "        trainY_dict = {\n",
    "            key: labels[train_index] for key, labels in clean_labels_dict.items()\n",
    "        }\n",
    "        testY_dict = {\n",
    "            key: labels[test_index] for key, labels in clean_labels_dict.items()\n",
    "        }\n",
    "    \n",
    "    num_classes_dict = {\n",
    "        key.replace('_output', ''): labels.shape[1] \n",
    "        for key, labels in trainY_dict.items()\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nFinal training shapes:\")\n",
    "        print(f\"trainX shape: {trainX.shape}\")\n",
    "        for name, labels in trainY_dict.items():\n",
    "            print(f\"{name} shape: {labels.shape}\")\n",
    "        print(\"\\nNumber of Classes:\")\n",
    "        for name, num_classes in num_classes_dict.items():\n",
    "            print(f\"{name}: {num_classes} classes\")\n",
    "    \n",
    "    return {\n",
    "        'trainX': trainX,\n",
    "        'trainY_dict': trainY_dict,\n",
    "        'testX': testX,\n",
    "        'testY_dict': testY_dict,\n",
    "        'num_classes_dict': num_classes_dict,\n",
    "        'label_binarizers': label_binarizers\n",
    "    }\n",
    "\n",
    "def create_branch(input_layer, num_classes, activation, name):\n",
    "    \"\"\"Create a classification branch with proper naming\"\"\"\n",
    "    base_name = name.replace('_output', '')\n",
    "    \n",
    "    x = Dense(512, activation='relu', name=f'{name}_dense1')(input_layer)\n",
    "    x = Dense(256, activation='relu', name=f'{name}_dense2')(x)\n",
    "    x = Dense(32, activation='relu', name=f'{name}_dense3')(x)\n",
    "    x = BatchNormalization(name=f'{name}_bn1')(x)\n",
    "    x = Dense(128, activation='relu', name=f'{name}_dense4')(x)\n",
    "    x = Dense(64, activation='relu', name=f'{name}_dense5')(x)\n",
    "    x = Dense(32, activation='relu', name=f'{name}_dense6')(x)\n",
    "    x = BatchNormalization(name=f'{name}_bn2')(x)\n",
    "    x = Dense(128, activation='relu', name=f'{name}_dense7')(x)\n",
    "    x = Dense(64, activation='relu', name=f'{name}_dense8')(x)\n",
    "    x = Dense(32, activation='relu', name=f'{name}_dense9')(x)\n",
    "    output = Dense(num_classes, activation=activation, name=f'{name}_output')(x)\n",
    "    return output\n",
    "\n",
    "def build_model(width, height, num_classes_dict):\n",
    "    \"\"\"Build the multi-output model\"\"\"\n",
    "    IMAGE_DIMS = (height, width, 3)\n",
    "    \n",
    "    base_model = ResNet50(weights='imagenet', \n",
    "                         include_top=False, \n",
    "                         input_shape=IMAGE_DIMS)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = Input(shape=IMAGE_DIMS, name='input_image')\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    outputs = {}\n",
    "    for task_name, num_classes in num_classes_dict.items():\n",
    "        output_name = f'{task_name}_output'\n",
    "        outputs[output_name] = create_branch(\n",
    "            x, \n",
    "            num_classes=num_classes,\n",
    "            activation='softmax',\n",
    "            name=task_name\n",
    "        )\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs\n",
    "    )\n",
    "    print(\"\\nModel output shapes with names:\")\n",
    "    for layer in model.output_names:\n",
    "        print(f\"{layer}: {model.get_layer(layer).output.shape}\")\n",
    "    return model\n",
    "\n",
    "def train_model(trainX, trainY_dict, testX, testY_dict, epochs=40, batch_size=32):\n",
    "    \"\"\"Train the multi-output fashion classification model\"\"\"\n",
    "    # Input validation\n",
    "    # assert trainX.shape[0] == list(trainY_dict.values())[0].shape[0], \"Inconsistent training data\"\n",
    "    # assert testX.shape[0] == list(testY_dict.values())[0].shape[0], \"Inconsistent test data\"\n",
    "\n",
    "    print(\"\\nTraining data shapes:\")\n",
    "    for name, labels in trainY_dict.items():\n",
    "        print(f\"{name}: {labels.shape}\")\n",
    "    \n",
    "    # Get number of classes for each task from the training data\n",
    "    num_classes_dict = {\n",
    "        name.replace('_output', ''): labels.shape[1]\n",
    "        for name, labels in trainY_dict.items()\n",
    "    }\n",
    "    print(\"\\nTask order:\")\n",
    "    for task_name in num_classes_dict.keys():\n",
    "        print(f\"{task_name}: {num_classes_dict[task_name]} classes\")\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model(180, 180, num_classes_dict)\n",
    "    \n",
    "    \n",
    "    losses = {name: \"categorical_crossentropy\" for name in trainY_dict.keys()}\n",
    "    metrics = {name: \"accuracy\" for name in trainY_dict.keys()}\n",
    "    \n",
    "\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss=losses, metrics=metrics)\n",
    "    \n",
    "   \n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    print(\"\\nInput shapes:\")\n",
    "    print(f\"trainX shape: {trainX.shape}\")\n",
    "    for name, y in trainY_dict.items():\n",
    "        print(f\"{name} shape: {y.shape}\")\n",
    "    \n",
    "\n",
    "    history = model.fit(\n",
    "        trainX,\n",
    "        trainY_dict,\n",
    "        validation_data=(testX, testY_dict),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "def run_fashion_classification_pipeline(\n",
    "    image_data,\n",
    "    df,\n",
    "    sample_size=15000,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    z_threshold=3,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"Complete pipeline for fashion classification\"\"\"\n",
    "    print(\"Input validation:\")\n",
    "    print(f\"Image data shape: {image_data.shape}\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Sample size requested: {sample_size}\")\n",
    "    \n",
    "    print(\"Starting data preparation...\")\n",
    "    data_prep_results = advanced_data_preparation(\n",
    "        image_data,\n",
    "        df,\n",
    "        sample_size=sample_size,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        z_threshold=z_threshold,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "   \n",
    "    trainX = data_prep_results['trainX']\n",
    "    trainY_dict = data_prep_results['trainY_dict']\n",
    "    testX = data_prep_results['testX']\n",
    "    testY_dict = data_prep_results['testY_dict']\n",
    "\n",
    "    print(\"\\nPrepared data shapes:\")\n",
    "    print(f\"trainX: {trainX.shape}\")\n",
    "    print(f\"testX: {testX.shape}\")\n",
    "    for name, labels in trainY_dict.items():\n",
    "        print(f\"train {name}: {labels.shape}\")\n",
    "    for name, labels in testY_dict.items():\n",
    "        print(f\"test {name}: {labels.shape}\")\n",
    "    \n",
    "    \n",
    "    print(\"\\nStarting model training...\")\n",
    "    model, history = train_model(\n",
    "        trainX,\n",
    "        trainY_dict,\n",
    "        testX,\n",
    "        testY_dict,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'data_prep_results': data_prep_results\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c57445d9-25d0-4dc3-885b-91d10d23682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_branch(input_layer, num_classes, activation, name):\n",
    "    \"\"\"Create a classification branch with proper naming\"\"\"\n",
    "    base_name = name.replace('_output', '')\n",
    "    \n",
    "    x = Dense(512, activation='relu', name=f'{name}_dense1')(input_layer)\n",
    "    x = Dense(256, activation='relu', name=f'{name}_dense2')(x)\n",
    "    x = Dense(32, activation='relu', name=f'{name}_dense3')(x)\n",
    "    x = BatchNormalization(name=f'{name}_bn1')(x)\n",
    "    x = Dense(128, activation='relu', name=f'{name}_dense4')(x)\n",
    "    x = Dense(64, activation='relu', name=f'{name}_dense5')(x)\n",
    "    x = Dense(32, activation='relu', name=f'{name}_dense6')(x)\n",
    "    x = BatchNormalization(name=f'{name}_bn2')(x)\n",
    "    x = Dense(128, activation='relu', name=f'{name}_dense7')(x)\n",
    "    x = Dense(64, activation='relu', name=f'{name}_dense8')(x)\n",
    "    x = Dense(32, activation='relu', name=f'{name}_dense9')(x)\n",
    "    output = Dense(num_classes, activation=activation, name=f'{name}_output')(x)\n",
    "    return output\n",
    "\n",
    "def build_model(width, height, num_classes_dict):\n",
    "    \"\"\"Build the multi-output model\"\"\"\n",
    "    IMAGE_DIMS = (height, width, 3)\n",
    "    \n",
    "    base_model = ResNet50(weights='imagenet', \n",
    "                         include_top=False, \n",
    "                         input_shape=IMAGE_DIMS)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = Input(shape=IMAGE_DIMS, name='input_image')\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    outputs = {}\n",
    "    for task_name, num_classes in num_classes_dict.items():\n",
    "        output_name = f'{task_name}_output'\n",
    "        outputs[output_name] = create_branch(\n",
    "            x, \n",
    "            num_classes=num_classes,\n",
    "            activation='softmax',\n",
    "            name=task_name\n",
    "        )\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=inputs,\n",
    "        outputs=outputs\n",
    "    )\n",
    "    print(\"\\nModel output shapes with names:\")\n",
    "    for layer in model.output_names:\n",
    "        print(f\"{layer}: {model.get_layer(layer).output.shape}\")\n",
    "    return model\n",
    "\n",
    "def train_model(trainX, trainY_dict, testX, testY_dict, epochs=40, batch_size=32):\n",
    "    \"\"\"Train the multi-output fashion classification model\"\"\"\n",
    "    # Input validation\n",
    "    # assert trainX.shape[0] == list(trainY_dict.values())[0].shape[0], \"Inconsistent training data\"\n",
    "    # assert testX.shape[0] == list(testY_dict.values())[0].shape[0], \"Inconsistent test data\"\n",
    "\n",
    "    print(\"\\nTraining data shapes:\")\n",
    "    for name, labels in trainY_dict.items():\n",
    "        print(f\"{name}: {labels.shape}\")\n",
    "    \n",
    "    # Get number of classes for each task from the training data\n",
    "    num_classes_dict = {\n",
    "        name.replace('_output', ''): labels.shape[1]\n",
    "        for name, labels in trainY_dict.items()\n",
    "    }\n",
    "    print(\"\\nTask order:\")\n",
    "    for task_name in num_classes_dict.keys():\n",
    "        print(f\"{task_name}: {num_classes_dict[task_name]} classes\")\n",
    "    \n",
    "    # Build model\n",
    "    model = build_model(180, 180, num_classes_dict)\n",
    "    \n",
    "    \n",
    "    losses = {name: \"categorical_crossentropy\" for name in trainY_dict.keys()}\n",
    "    metrics = {name: \"accuracy\" for name in trainY_dict.keys()}\n",
    "    \n",
    "\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss=losses, metrics=metrics)\n",
    "    \n",
    "   \n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    print(\"\\nInput shapes:\")\n",
    "    print(f\"trainX shape: {trainX.shape}\")\n",
    "    for name, y in trainY_dict.items():\n",
    "        print(f\"{name} shape: {y.shape}\")\n",
    "    \n",
    "\n",
    "    history = model.fit(\n",
    "        trainX,\n",
    "        trainY_dict,\n",
    "        validation_data=(testX, testY_dict),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def save_fashion_model(model, label_binarizers, num_classes_dict, save_path='fashion_model'):\n",
    "    \"\"\"\n",
    "    Save the fashion classification model and all necessary components\n",
    "    \n",
    "    Args:\n",
    "        model: trained Keras model\n",
    "        label_binarizers: dictionary of fitted LabelBinarizer objects\n",
    "        num_classes_dict: dictionary containing number of classes for each category\n",
    "        save_path: base path for saving model files\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "   \n",
    "    model.save(os.path.join(save_path, 'model.h5'))\n",
    "    \n",
    "   \n",
    "    with open(os.path.join(save_path, 'label_binarizers.pkl'), 'wb') as f:\n",
    "        pickle.dump(label_binarizers, f)\n",
    "    \n",
    "\n",
    "    with open(os.path.join(save_path, 'num_classes.json'), 'w') as f:\n",
    "        json.dump(num_classes_dict, f)\n",
    "    \n",
    "    print(f\"Model and components saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1248861-bfb7-4ad3-8687-d694ebc18b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = run_fashion_classification_pipeline(\n",
    "#     image_data,\n",
    "#     df,\n",
    "#     sample_size=13200,  \n",
    "#     epochs=10,\n",
    "#     batch_size=32,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "\n",
    "# model = results['model']\n",
    "# history = results['history']\n",
    "# data_prep_results = results['data_prep_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23494b6-28cd-44fa-b6c0-4ed4725d0f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "614bc9d7-a0f1-47c9-a5e6-0af1790f95d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "def save_fashion_model(model, label_binarizers, num_classes_dict, save_path='fashion_model'):\n",
    "    \"\"\"\n",
    "    Save the fashion classification model and all necessary components\n",
    "    \n",
    "    Args:\n",
    "        model: trained Keras model\n",
    "        label_binarizers: dictionary of fitted LabelBinarizer objects\n",
    "        num_classes_dict: dictionary containing number of classes for each category\n",
    "        save_path: base path for saving model files\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "   \n",
    "    model.save(os.path.join(save_path, 'model.h5'))\n",
    "    \n",
    "   \n",
    "    with open(os.path.join(save_path, 'label_binarizers.pkl'), 'wb') as f:\n",
    "        pickle.dump(label_binarizers, f)\n",
    "    \n",
    "\n",
    "    with open(os.path.join(save_path, 'num_classes.json'), 'w') as f:\n",
    "        json.dump(num_classes_dict, f)\n",
    "    \n",
    "    print(f\"Model and components saved to {save_path}\")\n",
    "\n",
    "def load_fashion_model(load_path='fashion_model'):\n",
    "    \"\"\"\n",
    "    Load the fashion classification model and all components\n",
    "    \n",
    "    Args:\n",
    "        load_path: path where model files are saved\n",
    "        \n",
    "    Returns:\n",
    "        model: loaded Keras model\n",
    "        label_binarizers: dictionary of fitted LabelBinarizer objects\n",
    "        num_classes_dict: dictionary containing number of classes for each category\n",
    "    \"\"\"\n",
    "    \n",
    "    model = load_model(os.path.join(load_path, 'model.h5'))\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(load_path, 'label_binarizers.pkl'), 'rb') as f:\n",
    "        label_binarizers = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(load_path, 'num_classes.json'), 'r') as f:\n",
    "        num_classes_dict = json.load(f)\n",
    "    \n",
    "    print(f\"Model and components loaded from {load_path}\")\n",
    "    return model, label_binarizers, num_classes_dict\n",
    "\n",
    "def predict_fashion_item(model, label_binarizers, image_array):\n",
    "    \"\"\"\n",
    "    Make predictions for a single fashion item\n",
    "    \n",
    "    Args:\n",
    "        model: loaded Keras model\n",
    "        label_binarizers: dictionary of fitted LabelBinarizer objects\n",
    "        image_array: preprocessed image array of shape (180, 180, 3)\n",
    "        \n",
    "    Returns:\n",
    "        predictions_dict: dictionary containing predictions for each category\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(image_array.shape) == 3:\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    \n",
    "    predictions = model.predict(image_array)\n",
    "   \n",
    "  \n",
    "    if not isinstance(predictions, dict):\n",
    "        raise ValueError(\"Model output is not a dictionary. Ensure the model is set up to output a dictionary.\")\n",
    "    predictions_dict = {}\n",
    "\n",
    "    for category, lb in label_binarizers.items():\n",
    "        prediction_key = f\"{category}_output\"\n",
    "        \n",
    "        \n",
    "        if prediction_key not in predictions:\n",
    "            raise ValueError(f\"Missing prediction for category: {category}\")\n",
    "        \n",
    "       \n",
    "        pred = predictions[prediction_key]\n",
    "        pred_class = np.argmax(pred)\n",
    "        \n",
    "        predictions_dict[category] = {\n",
    "            'label': lb.classes_[pred_class],\n",
    "            'confidence': float(pred[0][pred_class])\n",
    "        }\n",
    "    \n",
    "    \n",
    "\n",
    "    return predictions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c0f0ce7-9897-40b5-ba8c-cd570a97a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_fashion_model(load_path='fashion_model'):\n",
    "    \n",
    "    \n",
    "#     model = load_model(os.path.join(load_path, 'model.h5'))\n",
    "    \n",
    "    \n",
    "#     with open(os.path.join(load_path, 'label_binarizers.pkl'), 'rb') as f:\n",
    "#         label_binarizers = pickle.load(f)\n",
    "    \n",
    "    \n",
    "#     with open(os.path.join(load_path, 'num_classes.json'), 'r') as f:\n",
    "#         num_classes_dict = json.load(f)\n",
    "    \n",
    "#     print(f\"Model and components loaded from {load_path}\")\n",
    "#     return model, label_binarizers, num_classes_dict\n",
    "\n",
    "# model, label_binarizers, num_classes_dict = load_fashion_model(load_path=\"fashion_model\")\n",
    "\n",
    "# def preprocess_image(image_path, target_size=(180, 180)):\n",
    "#     \"\"\"\n",
    "#     Preprocess an image for prediction.\n",
    "#     Args:\n",
    "#         image_path: Path to the image file.\n",
    "#         target_size: Target size for resizing (default is 180x180).\n",
    "#     Returns:\n",
    "#         Preprocessed image array with batch dimension.\n",
    "#     \"\"\"\n",
    "#     img = load_img(image_path, target_size=target_size)  \n",
    "#     img_array = img_to_array(img) \n",
    "#     img_array = img_array / 255.0  \n",
    "#     img_array = np.expand_dims(img_array, axis=0) \n",
    "#     return img_array\n",
    "\n",
    "# IMAGE_DIMS = (180, 180, 3)\n",
    "# def load_image(imagePath):\n",
    "#     image = cv2.imread(imagePath)\n",
    "#     image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = preprocess_input(image)\n",
    "#     return image\n",
    "\n",
    "# def predict_fashion_item(model, label_binarizers, image_array):\n",
    "    \n",
    "#     if len(image_array.shape) == 3:\n",
    "#         image_array = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    \n",
    "#     predictions = model.predict(image_array)\n",
    "   \n",
    "  \n",
    "#     if not isinstance(predictions, dict):\n",
    "#         raise ValueError(\"Model output is not a dictionary. Ensure the model is set up to output a dictionary.\")\n",
    "#     predictions_dict = {}\n",
    "\n",
    "#     for category, lb in label_binarizers.items():\n",
    "#         prediction_key = f\"{category}_output\"\n",
    "        \n",
    "        \n",
    "#         if prediction_key not in predictions:\n",
    "#             raise ValueError(f\"Missing prediction for category: {category}\")\n",
    "        \n",
    "       \n",
    "#         pred = predictions[prediction_key]\n",
    "#         pred_class = np.argmax(pred)\n",
    "        \n",
    "#         predictions_dict[category] = {\n",
    "#             'label': lb.classes_[pred_class],\n",
    "#             'confidence': float(pred[0][pred_class])\n",
    "#         }\n",
    "    \n",
    "    \n",
    "\n",
    "#     return predictions_dict\n",
    "\n",
    "# model, label_binarizers, num_classes_dict = load_fashion_model('fashion_model')\n",
    "\n",
    "# image__path=r'images1\\a.jpg'\n",
    "\n",
    "\n",
    "# image = load_image(image__path)\n",
    "# predictions = predict_fashion_item(model, label_binarizers, image)\n",
    "\n",
    "# for category, pred in predictions.items():\n",
    "#     print(f\"{category}: {pred['label']} (confidence: {pred['confidence']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf65a5-b444-4361-933f-a9c5e62d68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save_fashion_model(\n",
    "#     model=results['model'],\n",
    "#     label_binarizers=data_prep_results['label_binarizers'],\n",
    "#     num_classes_dict=data_prep_results['num_classes_dict'],\n",
    "#     save_path='fashion_model'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e477c02d-816c-4d13-9469-3d84684894bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and components loaded from fashion_model\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "subCategory: Shoes (confidence: 1.00)\n",
      "gender: Men (confidence: 0.62)\n",
      "color: Red (confidence: 0.32)\n",
      "season: Spring (confidence: 0.39)\n",
      "usage: Casual (confidence: 1.00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, label_binarizers, num_classes_dict = load_fashion_model('fashion_model')\n",
    "\n",
    "image__path='images/2886.jpg'\n",
    "\n",
    "\n",
    "image = load_image(image__path)\n",
    "predictions = predict_fashion_item(model, label_binarizers, image)\n",
    "\n",
    "for category, pred in predictions.items():\n",
    "    print(f\"{category}: {pred['label']} (confidence: {pred['confidence']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b6e94-8c12-48d8-af91-f9af66e55689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_embedding_model(trained_model):\n",
    "    \"\"\"\n",
    "    Create a model that outputs embeddings from the trained model\n",
    "    \n",
    "    Args:\n",
    "        trained_model: The trained CNN model\n",
    "        \n",
    "    Returns:\n",
    "        Model that outputs embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_layer = None\n",
    "    for layer in reversed(trained_model.layers):\n",
    "      \n",
    "        if not layer.name.endswith('output') and not 'dense' in layer.name.lower():\n",
    "            embedding_layer = layer\n",
    "            break\n",
    "    \n",
    "    if embedding_layer is None:\n",
    "        raise ValueError(\"Could not find appropriate embedding layer\")\n",
    "    \n",
    "   \n",
    "    embedding_model = Model(\n",
    "        inputs=trained_model.input,\n",
    "        outputs=embedding_layer.output\n",
    "    )\n",
    "    \n",
    "    return embedding_model\n",
    "\n",
    "def extract_embeddings(model, images, batch_size=32):\n",
    "    \"\"\"\n",
    "    Extract embeddings for a set of images\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model or embedding model\n",
    "        images: Array of preprocessed images\n",
    "        batch_size: Batch size for processing\n",
    "        \n",
    "    Returns:\n",
    "        numpy array of embeddings\n",
    "    \"\"\"\n",
    "   \n",
    "    if any(layer.name.endswith('output') for layer in model.layers):\n",
    "        embedding_model = create_embedding_model(model)\n",
    "    else:\n",
    "        embedding_model = model\n",
    "    \n",
    "   \n",
    "    embeddings = embedding_model.predict(images, batch_size=batch_size)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b0f90-24a5-4fa7-9f07-29671ffa4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed=create_embedding_model(model)\n",
    "# embedding=extract_embeddings(embed,image_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced497f-c1d3-4bb7-b38d-14d3cefc1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_similar_items(selected_embedding, all_embeddings, top_k=5):\n",
    "    \"\"\"\n",
    "    Find the most similar items to a selected item using cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        selected_embedding: The embedding vector of the selected item\n",
    "        all_embeddings: Matrix of embeddings for all items\n",
    "        top_k: Number of similar items to return\n",
    "        \n",
    "    Returns:\n",
    "        List of indices of the most similar items\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(selected_embedding.shape) == 1:\n",
    "        selected_embedding = selected_embedding.reshape(1, -1)\n",
    "    \n",
    "    \n",
    "    similarities = cosine_similarity(selected_embedding, all_embeddings)\n",
    "    \n",
    "    similar_indices = np.argsort(similarities[0])[::-1][1:top_k+1]\n",
    "    \n",
    "    return similar_indices.tolist()\n",
    "\n",
    "def generate_outfit(selected_item_idx, clothing_item_embeddings, df, top_k=5):\n",
    "    \"\"\"\n",
    "    Generate an outfit based on a selected clothing item\n",
    "\n",
    "    Args:\n",
    "        selected_item_idx: Index of the selected item in the dataset\n",
    "        clothing_item_embeddings: Matrix of embeddings for all clothing items\n",
    "        df: DataFrame containing item details\n",
    "        top_k: Number of similar items to consider\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing the generated outfit\n",
    "    \"\"\"\n",
    "    print(\"\\nDebug: Starting generate_outfit function\")\n",
    "    print(f\"Debug: Selected item index: {selected_item_idx}\")\n",
    "    \n",
    "  \n",
    "    selected_item_embedding = clothing_item_embeddings[selected_item_idx]\n",
    "    selected_item = df.iloc[selected_item_idx]\n",
    "    print(f\"Debug: Selected item category: {selected_item['subCategory']}\")\n",
    "    \n",
    " \n",
    "    similarities = cosine_similarity(\n",
    "        selected_item_embedding.reshape(1, -1), \n",
    "        clothing_item_embeddings\n",
    "    )\n",
    "    similar_items_idx = np.argsort(similarities[0])[::-1][:top_k]\n",
    "    print(f\"Debug: Found {len(similar_items_idx)} similar items\")\n",
    "    \n",
    "   \n",
    "    category_groups = {\n",
    "        'top': [],\n",
    "        'bottom': [],\n",
    "        'shoes': [],\n",
    "        'accessory': []\n",
    "    }\n",
    "    \n",
    "   \n",
    "    category_mapping = {\n",
    "        # Tops\n",
    "        'Topwear': 'top',\n",
    "        'Shirts': 'top',\n",
    "        'T-shirts': 'top',\n",
    "        'Tshirts': 'top',\n",
    "        'Shirt': 'top',\n",
    "        'T-shirt': 'top',\n",
    "        'Top': 'top',\n",
    "        'Jacket': 'top',\n",
    "        'Sweater': 'top',\n",
    "        'Sweatshirt': 'top',\n",
    "        # Bottoms\n",
    "        'Bottomwear': 'bottom',\n",
    "        'Pants': 'bottom',\n",
    "        'Jeans': 'bottom',\n",
    "        'Shorts': 'bottom',\n",
    "        'Trousers': 'bottom',\n",
    "        'Skirt': 'bottom',\n",
    "        # Shoes\n",
    "        'Shoes': 'shoes',\n",
    "        'Footwear': 'shoes',\n",
    "        'Sneakers': 'shoes',\n",
    "        'Boots': 'shoes',\n",
    "        'Sandals': 'shoes',\n",
    "        # Accessories\n",
    "        'Accessory': 'accessory',\n",
    "        'Accessories': 'accessory',\n",
    "        'Watch': 'accessory',\n",
    "        'Belt': 'accessory',\n",
    "        'Bag': 'accessory',\n",
    "        'Wallet': 'accessory'\n",
    "    }\n",
    "    \n",
    "    print(\"\\nDebug: Grouping items by category\")\n",
    "    \n",
    "    selected_category = category_mapping.get(selected_item['subCategory'])\n",
    "    if selected_category:\n",
    "        category_groups[selected_category].append(selected_item_idx)\n",
    "        print(f\"Debug: Added selected item to {selected_category} category\")\n",
    "    \n",
    "    # Group similar items by categories\n",
    "    for idx in similar_items_idx:\n",
    "        item = df.iloc[idx]\n",
    "        category = category_mapping.get(item['subCategory'])\n",
    "        if category and idx != selected_item_idx:  # Avoid duplicating selected item\n",
    "            category_groups[category].append(idx)\n",
    "            print(f\"Debug: Added similar item {idx} to {category} category\")\n",
    "    \n",
    "    # Print category group sizes\n",
    "    for category, items in category_groups.items():\n",
    "        print(f\"Debug: {category} category has {len(items)} items\")\n",
    "    \n",
    "    # Generate outfit\n",
    "    outfit = {}\n",
    "    \n",
    "    # Helper function to add item to outfit\n",
    "    def add_item_to_outfit(category, item_idx):\n",
    "        outfit[category] = {\n",
    "            'item': df.iloc[item_idx],\n",
    "            'similarity_score': float(cosine_similarity(\n",
    "                selected_item_embedding.reshape(1, -1),\n",
    "                clothing_item_embeddings[item_idx].reshape(1, -1)\n",
    "            )[0][0])\n",
    "        }\n",
    "        print(f\"Debug: Added {category} item to outfit\")\n",
    "    \n",
    "    # Add selected item first\n",
    "    if selected_category:\n",
    "        add_item_to_outfit(selected_category, selected_item_idx)\n",
    "    \n",
    "    # Add items for other categories\n",
    "    for category, items in category_groups.items():\n",
    "        if category != selected_category and items:  # Skip selected item's category\n",
    "            add_item_to_outfit(category, items[0])  # Add first item from each category\n",
    "    \n",
    "    print(f\"Debug: Final outfit has {len(outfit)} items\")\n",
    "    return outfit\n",
    "\n",
    "def get_item_category(subcategory):\n",
    "    \"\"\"\n",
    "    Helper function to map subcategories to main categories\n",
    "    \n",
    "    Args:\n",
    "        subcategory: String representing the item's subcategory\n",
    "        \n",
    "    Returns:\n",
    "        String representing the main category\n",
    "    \"\"\"\n",
    "    category_mapping = {\n",
    "        'top': ['Shirt', 'Jacket', 'Top', 'T-shirt', 'Sweater', 'Blouse'],\n",
    "        'bottom': ['Pants', 'Shorts', 'Skirt', 'Jeans'],\n",
    "        'shoes': ['Shoes', 'Sneakers', 'Boots', 'Sandals'],\n",
    "        'accessory': ['Accessory', 'Bag', 'Belt', 'Hat', 'Jewelry']\n",
    "    }\n",
    "    \n",
    "    for category, subcategories in category_mapping.items():\n",
    "        if subcategory in subcategories:\n",
    "            return category\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df63df0a-38c2-49a7-b1bd-c062a665a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_outfit(outfit, save_path=None):\n",
    "    \"\"\"Display or save the recommended outfit images\"\"\"\n",
    "    num_items = len(outfit)\n",
    "    fig, axes = plt.subplots(1, num_items, figsize=(4*num_items, 4))\n",
    "    \n",
    "    if num_items == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, (category, item_data) in zip(axes, outfit.items()):\n",
    "        image = item_data['image']\n",
    "        \n",
    "        if image.max() <= 1.0:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "        \n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{category}\\n{item_data['item']['subCategory']}\\n\"\n",
    "                    f\"Similarity: {item_data['similarity_score']:.2f}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffa286-4f24-4f1a-b079-2baa6a9a8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(embeddings, file_path):\n",
    "    \"\"\"Save embeddings to a file.\"\"\"\n",
    "    np.save(file_path, embeddings)\n",
    "def load_embeddings(file_path):\n",
    "    \"\"\"Load embeddings from a file.\"\"\"\n",
    "    return np.load(file_path)\n",
    "\n",
    "def compute_and_save_embeddings(embedding_model, image_data, save_path):\n",
    "    \"\"\"\n",
    "        Compute embeddings for all images and save them to a file.\n",
    "        \n",
    "        Args:\n",
    "            embedding_model: The embedding model\n",
    "            image_data: NumPy array of processed images\n",
    "            save_path: Path to save the embeddings\n",
    "    \"\"\"\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Loading precomputed embeddings from {save_path}...\")\n",
    "        embeddings = load_embeddings(save_path)\n",
    "    else:\n",
    "        print(\"Computing embeddings...\")\n",
    "        embeddings = embedding_model.predict(np.array(image_data), batch_size=32)\n",
    "        save_embeddings(embeddings, save_path)\n",
    "        print(f\"Embeddings saved to {save_path}.\")\n",
    "        \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "    \n",
    "# \n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e2685-d1f2-4acd-ac84-cd91ab438f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def process_input_image(image_path, classification_model, label_binarizers):\n",
    "    \"\"\"\n",
    "    Process a single input image and extract its features\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        classification_model: Trained multi-label classification model\n",
    "        label_binarizers: Dictionary of label binarizers\n",
    "        \n",
    "    Returns:\n",
    "        dict: Extracted features with confidence scores\n",
    "        array: Preprocessed image\n",
    "    \"\"\"\n",
    "\n",
    "    image = load_image(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Could not load input image\")\n",
    "    \n",
    "\n",
    "    image_batch = np.expand_dims(image, axis=0)\n",
    "    predictions = predict_fashion_item(classification_model, label_binarizers, image_batch)\n",
    "    \n",
    "    return predictions, image\n",
    "\n",
    "def create_embedding_model(trained_model):\n",
    "    \"\"\"\n",
    "    Create a model that outputs embeddings from the trained model\n",
    "    \"\"\"\n",
    "  \n",
    "    embedding_layer = None\n",
    "    for layer in reversed(trained_model.layers):\n",
    "        if not layer.name.endswith('output') and not 'dense' in layer.name.lower():\n",
    "            embedding_layer = layer\n",
    "            break\n",
    "    \n",
    "    if embedding_layer is None:\n",
    "        raise ValueError(\"Could not find appropriate embedding layer\")\n",
    "    \n",
    " \n",
    "    embedding_model = Model(\n",
    "        inputs=trained_model.input,\n",
    "        outputs=embedding_layer.output\n",
    "    )\n",
    "    \n",
    "    return embedding_model\n",
    "\n",
    "def filter_similar_items(similar_items_idx, df, input_features, min_confidence=0.7):\n",
    "    \"\"\"\n",
    "    Filter similar items based on classification features\n",
    "    \n",
    "    Args:\n",
    "        similar_items_idx: List of indices of similar items\n",
    "        df: DataFrame containing item metadata\n",
    "        input_features: Features extracted from input image\n",
    "        min_confidence: Minimum confidence score to consider a feature match\n",
    "    \n",
    "    Returns:\n",
    "        List of filtered item indices\n",
    "    \"\"\"\n",
    "    filtered_idx = []\n",
    "    \n",
    "    # Get high-confidence features from input\n",
    "    important_features = {\n",
    "        k: v['label'] for k, v in input_features.items() \n",
    "        if float(v['confidence']) >= min_confidence\n",
    "    }\n",
    "    \n",
    "    for idx in similar_items_idx:\n",
    "        item = df.iloc[idx]\n",
    "        # Check if item matches important features\n",
    "        matches = True\n",
    "        for feature, value in important_features.items():\n",
    "            if feature in ['gender', 'usage', 'season']:\n",
    "                # Convert to string and compare\n",
    "                if str(item[feature]).lower() != str(value).lower():\n",
    "                    matches = False\n",
    "                    break\n",
    "        if matches:\n",
    "            filtered_idx.append(idx)\n",
    "    \n",
    "    # If no matches found, return original indices\n",
    "    return filtered_idx if filtered_idx else list(similar_items_idx)\n",
    "\n",
    "def generate_outfit(selected_item_idx, clothing_item_embeddings, df, top_k=10):\n",
    "    \"\"\"\n",
    "    Generate an outfit ensuring items from different categories are selected\n",
    "    \n",
    "    Args:\n",
    "        selected_item_idx: Index of the selected item\n",
    "        clothing_item_embeddings: Matrix of embeddings for all items\n",
    "        df: DataFrame containing item metadata\n",
    "        top_k: Number of similar items to consider\n",
    "    \"\"\"\n",
    "    print(\"\\nDebug: Starting generate_outfit function\")\n",
    "    \n",
    "    # Get selected item's embedding and features\n",
    "    selected_embedding = clothing_item_embeddings[selected_item_idx]\n",
    "    selected_item = df.iloc[selected_item_idx]\n",
    "    \n",
    "    # Calculate similarities with all items\n",
    "    similarities = cosine_similarity(\n",
    "        selected_embedding.reshape(1, -1), \n",
    "        clothing_item_embeddings\n",
    "    )[0]\n",
    "    \n",
    "    # Get all items sorted by similarity\n",
    "    all_items_idx = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Initialize category groups\n",
    "    category_groups = {\n",
    "        'top': [],\n",
    "        'bottom': [],\n",
    "        'shoes': [],\n",
    "        'accessory': []\n",
    "    }\n",
    "    \n",
    "    # Map subcategories to main categories\n",
    "    category_mapping = {\n",
    "        'top': ['Topwear', 'Shirt', 'T-shirt', 'Top'],\n",
    "        'bottom': ['Bottomwear', 'Pants', 'Jeans', 'Shorts', 'Skirt'],\n",
    "        'shoes': ['Shoes', 'Footwear', 'Sneakers', 'Sandals', 'Flip Flops'],\n",
    "        'accessory': ['Accessories', 'Watch', 'Belt', 'Wallet', 'Bag']\n",
    "    }\n",
    "    \n",
    "    # Get selected item's features\n",
    "    selected_gender = df.iloc[selected_item_idx]['gender']\n",
    "    selected_usage = df.iloc[selected_item_idx]['usage']\n",
    "    \n",
    "    # Function to get main category\n",
    "    def get_main_category(subcategory):\n",
    "        for main_cat, sub_cats in category_mapping.items():\n",
    "            if any(sub.lower() in subcategory.lower() for sub in sub_cats):\n",
    "                return main_cat\n",
    "        return None\n",
    "    \n",
    "    # First, add the selected item to its category\n",
    "    selected_category = get_main_category(selected_item['subCategory'])\n",
    "    if selected_category:\n",
    "        category_groups[selected_category].append({\n",
    "            'idx': selected_item_idx,\n",
    "            'similarity': 1.0\n",
    "        })\n",
    "    \n",
    "    print(f\"Debug: Selected item category: {selected_category}\")\n",
    "    \n",
    "    # Then find items for other categories\n",
    "    items_per_category = 5  # Number of items to collect per category\n",
    "    \n",
    "    for idx in all_items_idx:\n",
    "        item = df.iloc[idx]\n",
    "        \n",
    "        # Skip if it's the selected item\n",
    "        if idx == selected_item_idx:\n",
    "            continue\n",
    "            \n",
    "        # Only consider items matching gender and usage\n",
    "        if item['gender'] != selected_gender or item['usage'] != selected_usage:\n",
    "            continue\n",
    "        \n",
    "        # Get the main category for this item\n",
    "        main_category = get_main_category(item['subCategory'])\n",
    "        if main_category and len(category_groups[main_category]) < items_per_category:\n",
    "            category_groups[main_category].append({\n",
    "                'idx': idx,\n",
    "                'similarity': similarities[idx]\n",
    "            })\n",
    "    \n",
    "    # Print debug information\n",
    "    for category, items in category_groups.items():\n",
    "        print(f\"Debug: {category} category has {len(items)} items\")\n",
    "    \n",
    "    # Create final outfit by selecting top item from each category\n",
    "    outfit = {}\n",
    "    for category, items in category_groups.items():\n",
    "        if items:  \n",
    "           \n",
    "            if category == selected_category:\n",
    "                item_data = items[0]  \n",
    "            else:\n",
    "             \n",
    "                item_data = max(items, key=lambda x: x['similarity'])\n",
    "            \n",
    "            outfit[category] = {\n",
    "                'item': df.iloc[item_data['idx']],\n",
    "                'similarity_score': item_data['similarity']\n",
    "            }\n",
    "            print(f\"Debug: Added {category} item to outfit\")\n",
    "    \n",
    "    print(f\"Debug: Final outfit has {len(outfit)} items\")\n",
    "    return outfit\n",
    "\n",
    "def generate_complete_outfit(image_path, classification_model, label_binarizers, \n",
    "                           embedding_model, image_data, df, top_k=10):\n",
    "    \"\"\"Generate a complete outfit based on a single input image\"\"\"\n",
    "    print(\"\\nStarting outfit generation process...\")\n",
    "    \n",
    " \n",
    "    print(\"Processing input image...\")\n",
    "    input_features, processed_image = process_input_image(\n",
    "        image_path, classification_model, label_binarizers\n",
    "    )\n",
    "    print(\"Input features extracted:\", input_features)\n",
    "    \n",
    "  \n",
    "    original_input_image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "   \n",
    "    print(\"\\nGenerating embeddings for input image...\")\n",
    "    input_embedding = embedding_model.predict(np.expand_dims(processed_image, axis=0))\n",
    "    \n",
    "    # print(\"Generating embeddings for all images...\")\n",
    "    # all_embeddings = embedding_model.predict(np.array(image_data), batch_size=32)\n",
    "    embeddings_save_path = \"precomputed_embeddings.npy\"\n",
    "    all_embeddings = compute_and_save_embeddings(embedding_model, image_data, embeddings_save_path)\n",
    "\n",
    "   \n",
    "    print(\"\\nFinding similar items...\")\n",
    "    similarities = cosine_similarity(input_embedding, all_embeddings)\n",
    "    similar_items_idx = np.argsort(similarities[0])[::-1][:top_k]\n",
    "    print(f\"Found {len(similar_items_idx)} similar items\")\n",
    "    \n",
    "  \n",
    "    print(\"\\nFiltering similar items...\")\n",
    "    filtered_items_idx = filter_similar_items(\n",
    "        similar_items_idx, df, input_features\n",
    "    )\n",
    "    print(f\"Filtered to {len(filtered_items_idx)} items\")\n",
    "    \n",
    "    if not filtered_items_idx:\n",
    "        print(\"Warning: No items found after filtering!\")\n",
    "        return {}, input_features, original_input_image\n",
    "    \n",
    "   \n",
    "    print(\"\\nGenerating outfit...\")\n",
    "    outfit = generate_outfit(\n",
    "        selected_item_idx=filtered_items_idx[0],\n",
    "        clothing_item_embeddings=all_embeddings,\n",
    "        df=df,\n",
    "        top_k=top_k\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nOutfit generated with {len(outfit)} items\")\n",
    "    \n",
    "    \n",
    "    print(\"Adding images to outfit...\")\n",
    "    for category, item_data in outfit.items():\n",
    "        try:\n",
    "            idx = df.index.get_loc(item_data['item'].name)\n",
    "            outfit[category]['image'] = image_data[idx]\n",
    "            print(f\"Added image for {category}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding image for {category}: {str(e)}\")\n",
    "    \n",
    "    return outfit, input_features, original_input_image\n",
    "\n",
    "# def main(image_data, df):\n",
    "#     print(\"\\nInitializing main function...\")\n",
    "#     print(f\"Image data shape: {image_data.shape}\")\n",
    "#     print(f\"DataFrame shape: {df.shape}\")\n",
    "    \n",
    "#     matcher, _, _, _ = setup_matcher(\n",
    "#     classification_model_path='fashion_model',\n",
    "#     image_dir=\"images1\"\n",
    "#     )\n",
    "  \n",
    "#     print(\"\\nLoading models...\")\n",
    "#     classification_model, label_binarizers, num_classes_dict = load_fashion_model('fashion_model')\n",
    "#     embedding_model = create_embedding_model(classification_model)\n",
    "    \n",
    "#     input_image_path = \"images/abc.jpg\"\n",
    "#     print(f\"\\nProcessing input image: {input_image_path}\")\n",
    "    \n",
    "    \n",
    "#     outfit, input_features, input_image = generate_complete_outfit(\n",
    "#         image_path=input_image_path,\n",
    "#         classification_model=classification_model,\n",
    "#         label_binarizers=label_binarizers,\n",
    "#         embedding_model=embedding_model,\n",
    "#         image_data=image_data,\n",
    "#         df=df\n",
    "#     )\n",
    "    \n",
    "#     if not outfit:\n",
    "#         print(\"\\nNo outfit was generated!\")\n",
    "#         return\n",
    "    \n",
    "\n",
    "#     print(\"\\nInput Item Features:\")\n",
    "#     for feature, data in input_features.items():\n",
    "#         print(f\"{feature}: {data['label']} (confidence: {data['confidence']:.2f})\")\n",
    "    \n",
    "\n",
    "#     print(\"\\nDisplaying outfit...\")\n",
    "#     display_outfit(outfit)\n",
    "    \n",
    "\n",
    "#     print(\"\\nRecommended Outfit Details:\")\n",
    "#     for category, item_data in outfit.items():\n",
    "#         print(f\"\\n{category.upper()}:\")\n",
    "#         print(f\"Item: {item_data['item']['subCategory']}\")\n",
    "#         print(f\"Color: {item_data['item'].get('color', 'N/A')}\")\n",
    "#         print(f\"Similarity Score: {item_data['similarity_score']:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     main(image_data, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633e41e-9c84-44b6-8f01-cfef72529667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class ImageMatcher:\n",
    "    def __init__(self, classification_model, embedding_model, label_binarizers, base_image_dir, cache_dir='./features_cache'):\n",
    "        \"\"\"\n",
    "        Initialize the comprehensive image matching system\n",
    "        \n",
    "        Args:\n",
    "            classification_model: Trained classification model\n",
    "            embedding_model: Model for feature extraction\n",
    "            label_binarizers: Dictionary of label binarizers for each category\n",
    "            base_image_dir: Path to the main images directory\n",
    "            cache_dir: Directory to store processed image features\n",
    "        \"\"\"\n",
    "        self.base_image_dir = Path(base_image_dir)\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.classification_model = classification_model\n",
    "        self.embedding_model = embedding_model\n",
    "        self.label_binarizers = label_binarizers\n",
    "        \n",
    "        # Cache paths\n",
    "        self.cache_metadata_path = self.cache_dir / 'cache_metadata.json'\n",
    "        self.category_index_path = self.cache_dir / 'category_index.json'\n",
    "        self.metadata_path = self.cache_dir / 'generated_metadata.json'\n",
    "        self.category_stats_path = self.cache_dir / 'category_statistics.json'\n",
    "        \n",
    "        # Initialize data structures\n",
    "        self.image_features = {}\n",
    "        self.category_index = {}\n",
    "        self.metadata = {}\n",
    "        self.category_stats = {}\n",
    "        self.loaded_categories = set()\n",
    "        \n",
    "        # Load or initialize metadata\n",
    "        self.load_cache_metadata()\n",
    "        self.generate_or_load_metadata()\n",
    "        \n",
    "    def load_cache_metadata(self):\n",
    "        \"\"\"Load or initialize cache metadata\"\"\"\n",
    "        if self.cache_metadata_path.exists():\n",
    "            with open(self.cache_metadata_path, 'r') as f:\n",
    "                self.cache_metadata = json.load(f)\n",
    "        else:\n",
    "            self.cache_metadata = {\n",
    "                'last_update': None,\n",
    "                'processed_images': {}\n",
    "            }\n",
    "    \n",
    "    def generate_or_load_metadata(self):\n",
    "        \"\"\"Generate or load metadata and category statistics\"\"\"\n",
    "        if self.metadata_path.exists():\n",
    "            print(\"Loading existing metadata...\")\n",
    "            with open(self.metadata_path, 'r') as f:\n",
    "                self.metadata = json.load(f)\n",
    "            with open(self.category_stats_path, 'r') as f:\n",
    "                self.category_stats = json.load(f)\n",
    "            print(f\"Loaded metadata for {len(self.metadata)} images\")\n",
    "            self._print_category_statistics()\n",
    "        else:\n",
    "            print(\"Generating new metadata for all images...\")\n",
    "            self._generate_metadata()\n",
    "    \n",
    "    def _generate_metadata(self):\n",
    "        \"\"\"Process all images to generate metadata and category statistics\"\"\"\n",
    "        batch_size = 32\n",
    "        all_images = list(Path(self.base_image_dir).rglob('*.[jJ][pP][gG]'))\n",
    "        total_images = len(all_images)\n",
    "        \n",
    "        self.category_stats = {\n",
    "            'total_images': total_images,\n",
    "            'categories': {},\n",
    "            'category_combinations': {}\n",
    "        }\n",
    "        \n",
    "        print(f\"Processing {total_images} images...\")\n",
    "        \n",
    "        for i in tqdm(range(0, total_images, batch_size), desc=\"Generating metadata\"):\n",
    "            batch_paths = all_images[i:i + batch_size]\n",
    "            batch_arrays = []\n",
    "            valid_paths = []\n",
    "            \n",
    "            for path in batch_paths:\n",
    "                try:\n",
    "                    img_array = self.preprocess_image(path)\n",
    "                    if img_array is not None:\n",
    "                        batch_arrays.append(img_array[0])\n",
    "                        valid_paths.append(path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error preprocessing image {path}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if batch_arrays:\n",
    "                try:\n",
    "                    batch_array = np.array(batch_arrays)\n",
    "                    features = self.extract_features(batch_array)\n",
    "                    \n",
    "                    for idx, path in enumerate(valid_paths):\n",
    "                        try:\n",
    "                            article_id = path.stem\n",
    "                            \n",
    "                            # Add debugging output\n",
    "                            print(f\"Processing {article_id}\")\n",
    "                            print(\"Classifications shape:\", \n",
    "                                  np.array(features['classifications'][idx]).shape)\n",
    "                            \n",
    "                            categories = self._process_predictions(features['classifications'][idx])\n",
    "                            \n",
    "                            # Store metadata\n",
    "                            self.metadata[article_id] = {\n",
    "                                'path': str(path),\n",
    "                                'categories': categories['categories'],\n",
    "                                'confidence_scores': categories['scores'],\n",
    "                                'primary_category': categories['primary_category']\n",
    "                            }\n",
    "                            \n",
    "                            # Update category statistics\n",
    "                            self._update_category_stats(categories['categories'])\n",
    "                            \n",
    "                            # Cache features\n",
    "                            feature_path = self.cache_dir / f\"{article_id}_features.npz\"\n",
    "                            np.savez(\n",
    "                                feature_path,\n",
    "                                classifications=features['classifications'][idx],\n",
    "                                embeddings=features['embeddings'][idx]\n",
    "                            )\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing image {path}: {e}\")\n",
    "                            continue\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing batch: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        self._finalize_statistics()\n",
    "        self._save_metadata()\n",
    "        \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess image for model input\"\"\"\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            img = img.convert('RGB')\n",
    "            img = img.resize((180, 180))\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array / 255.0\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            return img_array\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_features(self, image_array):\n",
    "        \"\"\"Extract features using both models\"\"\"\n",
    "        # Get raw predictions\n",
    "        classifications = self.classification_model.predict(image_array)\n",
    "        embeddings = self.embedding_model.predict(image_array)\n",
    "        \n",
    "        # Ensure consistent format for classifications\n",
    "        if isinstance(classifications, dict):\n",
    "        # If classifications is a dictionary, take the first key's predictions\n",
    "            pred_key = list(classifications.keys())[0]\n",
    "            classifications = classifications[pred_key]\n",
    "    \n",
    "        classifications = np.array(classifications)\n",
    "    \n",
    "        if len(image_array.shape) == 3:  # Single image\n",
    "            return {\n",
    "                'classifications': [classifications],\n",
    "                'embeddings': [embeddings] if isinstance(embeddings, np.ndarray) else embeddings\n",
    "            }\n",
    "        else:  # Batch of images\n",
    "            return {\n",
    "                'classifications': [classifications[i] if classifications.ndim > 1 else classifications \n",
    "                              for i in range(len(image_array))],\n",
    "                'embeddings': embeddings\n",
    "            }\n",
    "    \n",
    "    def _process_predictions(self, predictions):\n",
    "        \"\"\"Process model predictions into categories with confidence scores\"\"\"\n",
    "        threshold = 0.3\n",
    "        categories = []\n",
    "        scores = {}\n",
    "        \n",
    "        # Add debugging output\n",
    "        print(\"Predictions type:\", type(predictions))\n",
    "        print(\"Predictions shape:\", np.array(predictions).shape)\n",
    "        print(\"Predictions content:\", predictions)\n",
    "        \n",
    "        # Convert predictions to numpy array if needed\n",
    "        if not isinstance(predictions, np.ndarray):\n",
    "            predictions = np.array(predictions)\n",
    "        \n",
    "        # Ensure predictions is 1-dimensional\n",
    "        predictions = predictions.flatten()\n",
    "        \n",
    "        category_names = ['mens', 'womens', 'children', 'shirts', 'pants', 'shoes', 'accessories']\n",
    "        for idx, score in enumerate(predictions[:len(category_names)]):\n",
    "            if score > threshold:\n",
    "                cat = category_names[idx]\n",
    "                categories.append(cat)\n",
    "                scores[cat] = float(score)\n",
    "        \n",
    "        primary_category = max(scores.items(), key=lambda x: x[1])[0] if scores else None\n",
    "    \n",
    "        return {\n",
    "            'categories': categories,\n",
    "            'scores': scores,\n",
    "            'primary_category': primary_category\n",
    "        }\n",
    "    def _update_category_stats(self, categories):\n",
    "        \"\"\"Update category statistics\"\"\"\n",
    "        for cat in categories:\n",
    "            if cat not in self.category_stats['categories']:\n",
    "                self.category_stats['categories'][cat] = 0\n",
    "            self.category_stats['categories'][cat] += 1\n",
    "        \n",
    "        combo = '+'.join(sorted(categories))\n",
    "        if combo not in self.category_stats['category_combinations']:\n",
    "            self.category_stats['category_combinations'][combo] = 0\n",
    "        self.category_stats['category_combinations'][combo] += 1\n",
    "    \n",
    "    def _finalize_statistics(self):\n",
    "        \"\"\"Finalize category statistics with percentages\"\"\"\n",
    "        total = self.category_stats['total_images']\n",
    "        for cat, count in self.category_stats['categories'].items():\n",
    "            self.category_stats['categories'][cat] = {\n",
    "                'count': count,\n",
    "                'percentage': (count / total) * 100\n",
    "            }\n",
    "    \n",
    "    def _save_metadata(self):\n",
    "        \"\"\"Save all metadata to files\"\"\"\n",
    "        with open(self.metadata_path, 'w') as f:\n",
    "            json.dump(self.metadata, f)\n",
    "        with open(self.category_stats_path, 'w') as f:\n",
    "            json.dump(self.category_stats, f)\n",
    "        with open(self.cache_metadata_path, 'w') as f:\n",
    "            json.dump(self.cache_metadata, f)\n",
    "    \n",
    "    def find_similar_images(self, query_features, categories=None, top_k=5):\n",
    "        \"\"\"\n",
    "        Find similar images with optional category filtering\n",
    "        \n",
    "        Args:\n",
    "            query_features: Features of the query image\n",
    "            categories: Optional list of categories to search within\n",
    "            top_k: Number of matches to return\n",
    "        \"\"\"\n",
    "        if categories:\n",
    "            self.load_category_features(categories)\n",
    "        \n",
    "        similarities = {}\n",
    "        query_embedding = query_features['embeddings'].flatten()\n",
    "        query_classifications = query_features['classifications']\n",
    "        \n",
    "        for article_id, features in self.image_features.items():\n",
    "            if categories and not any(cat in self.metadata[article_id]['categories'] \n",
    "                                    for cat in categories):\n",
    "                continue\n",
    "            \n",
    "            db_embedding = features['embeddings'].flatten()\n",
    "            embedding_similarity = float(\n",
    "                np.dot(query_embedding, db_embedding) / (\n",
    "                    np.linalg.norm(query_embedding) * np.linalg.norm(db_embedding)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            classification_similarity = self._calculate_classification_similarity(\n",
    "                query_classifications, features['classifications']\n",
    "            )\n",
    "            \n",
    "            similarity = (0.6 * embedding_similarity + 0.4 * classification_similarity)\n",
    "            similarities[article_id] = {\n",
    "                'total': float(similarity),\n",
    "                'embedding': float(embedding_similarity),\n",
    "                'classification': float(classification_similarity)\n",
    "            }\n",
    "        \n",
    "        return self._get_top_matches(similarities, top_k)\n",
    "    \n",
    "    def _calculate_classification_similarity(self, query_pred, db_pred):\n",
    "        \"\"\"Calculate similarity between classification predictions\"\"\"\n",
    "        if isinstance(query_pred, dict):\n",
    "            query_pred = next(iter(query_pred.values()))\n",
    "        if isinstance(db_pred, dict):\n",
    "            db_pred = next(iter(db_pred.values()))\n",
    "            \n",
    "        query_pred = np.array(query_pred).flatten()\n",
    "        db_pred = np.array(db_pred).flatten()\n",
    "        \n",
    "        if np.any(query_pred) and np.any(db_pred):\n",
    "            return float(\n",
    "                np.dot(query_pred, db_pred) / (\n",
    "                    np.linalg.norm(query_pred) * np.linalg.norm(db_pred)\n",
    "                )\n",
    "            )\n",
    "        return 0.0\n",
    "    \n",
    "    def _get_top_matches(self, similarities, top_k):\n",
    "        \"\"\"Get top k matches with detailed information\"\"\"\n",
    "        sorted_items = sorted(\n",
    "            similarities.items(),\n",
    "            key=lambda x: x[1]['total'],\n",
    "            reverse=True\n",
    "        )[:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for article_id, scores in sorted_items:\n",
    "            result = {\n",
    "                'article_id': article_id,\n",
    "                'similarity_score': scores['total'],\n",
    "                'embedding_sim': scores['embedding'],\n",
    "                'classification_sim': scores['classification'],\n",
    "                'image_path': str(self.metadata[article_id]['path']),\n",
    "                'categories': self.metadata[article_id]['categories'],\n",
    "                'confidence_scores': self.metadata[article_id]['confidence_scores']\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_matches(self, query_image_path, matches, title=\"Matching Results\"):\n",
    "        \"\"\"Visualize matching results with detailed information\"\"\"\n",
    "        n_matches = len(matches)\n",
    "        fig = plt.figure(figsize=(15, 8))\n",
    "        \n",
    "        # Query image\n",
    "        plt.subplot(2, n_matches + 1, 1)\n",
    "        query_img = Image.open(query_image_path)\n",
    "        plt.imshow(query_img)\n",
    "        plt.title(\"Query Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Matches\n",
    "        for idx, match in enumerate(matches):\n",
    "            # Image\n",
    "            plt.subplot(2, n_matches + 1, idx + 2)\n",
    "            try:\n",
    "                img = Image.open(match['image_path'])\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Match {idx + 1}\\nScore: {match['similarity_score']:.2f}\")\n",
    "            except Exception as e:\n",
    "                plt.text(0.5, 0.5, f\"Error loading image:\\n{str(e)}\", \n",
    "                        ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Details\n",
    "            plt.subplot(2, n_matches + 1, n_matches + idx + 3)\n",
    "            details = (f\"Embedding: {match['embedding_sim']:.2f}\\n\"\n",
    "                      f\"Classification: {match['classification_sim']:.2f}\\n\"\n",
    "                      f\"Categories: {', '.join(match['categories'])}\")\n",
    "            plt.text(0.5, 0.5, details, ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(title)\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def get_recommendations(self, input_image_path, categories=None, top_k=5):\n",
    "        \"\"\"\n",
    "        Get recommendations for an input image\n",
    "        \n",
    "        Args:\n",
    "            input_image_path: Path to the query image\n",
    "            categories: Optional list of categories to search within\n",
    "            top_k: Number of recommendations to return\n",
    "        \"\"\"\n",
    "        input_array = self.preprocess_image(input_image_path)\n",
    "        if input_array is None:\n",
    "            raise ValueError(\"Could not process input image\")\n",
    "            \n",
    "        input_features = self.extract_features(input_array)\n",
    "        matches = self.find_similar_images(input_features, categories, top_k)\n",
    "        \n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6406ce-33b3-43ea-8439-f632b82c2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model, label_binarizers, num_classes_dict = load_fashion_model('fashion_model')\n",
    "embedding_model = create_embedding_model(classification_model)\n",
    "\n",
    "matcher = ImageMatcher(\n",
    "    classification_model=classification_model,\n",
    "    embedding_model=embedding_model,\n",
    "    label_binarizers=label_binarizers,\n",
    "    base_image_dir='images1'\n",
    ")\n",
    "\n",
    "recommendations = matcher.get_recommendations(\n",
    "    input_image_path='images/28865.jpg',\n",
    "    # categories=['shirts', 'pants'],  # optional\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "matcher.visualize_matches(\n",
    "    query_image_path='images/28865.jpg',\n",
    "    matches=recommendations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67beff91-952a-400a-bc3a-2d73661614d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a659cc7-2650-4852-9f5f-513abd05cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e435c62-8e0f-4333-ab37-15ac2a84e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e46df-9f6d-44ad-aa11-9c7edf4121d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e5e4f-315f-4f6f-8cd6-469dce325368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93a48f-52f6-4106-a25d-ebc50d647502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# from PIL import Image\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model, load_model\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "# class EnhancedImageMatcher:\n",
    "#     def __init__(self, classification_model, embedding_model, label_binarizers, base_image_dir, cache_dir='./features_cache'):\n",
    "#         \"\"\"\n",
    "#         Initialize the matching system with complete model setup\n",
    "        \n",
    "#         Args:\n",
    "#             classification_model: Your trained classification model\n",
    "#             embedding_model: Your embedding model for feature extraction\n",
    "#             label_binarizers: Dictionary of label binarizers for each category\n",
    "#             base_image_dir: Path to the main images directory\n",
    "#             cache_dir: Directory to store processed image features\n",
    "#         \"\"\"\n",
    "#         self.base_image_dir = Path(base_image_dir)\n",
    "#         self.cache_dir = Path(cache_dir)\n",
    "#         self.cache_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "#         self.classification_model = classification_model\n",
    "#         self.embedding_model = embedding_model\n",
    "#         self.label_binarizers = label_binarizers\n",
    "        \n",
    "#         self.cache_metadata_path = self.cache_dir / 'cache_metadata.json'\n",
    "#         self.load_cache_metadata()\n",
    "        \n",
    "#         self.map_available_images()\n",
    "\n",
    "#     def extract_features(self, image_array):\n",
    "#         \"\"\"Extract features using both classification and embedding models\"\"\"\n",
    "#         classifications = self.classification_model.predict(image_array)\n",
    "#         if not isinstance(classifications, dict):\n",
    "#             classifications = {'prediction': classifications}\n",
    "            \n",
    "#         embeddings = self.embedding_model.predict(image_array)\n",
    "        \n",
    "#         return {\n",
    "#             'classifications': classifications,\n",
    "#             'embeddings': embeddings\n",
    "#         }\n",
    "    \n",
    "#     def load_cache_metadata(self):\n",
    "#         \"\"\"Load or initialize cache metadata\"\"\"\n",
    "#         if self.cache_metadata_path.exists():\n",
    "#             with open(self.cache_metadata_path, 'r') as f:\n",
    "#                 self.cache_metadata = json.load(f)\n",
    "#         else:\n",
    "#             self.cache_metadata = {\n",
    "#                 'last_update': None,\n",
    "#                 'processed_images': {}\n",
    "#             }\n",
    "    \n",
    "#     def save_cache_metadata(self):\n",
    "#         \"\"\"Save cache metadata\"\"\"\n",
    "#         with open(self.cache_metadata_path, 'w') as f:\n",
    "#             json.dump(self.cache_metadata, f)\n",
    "    \n",
    "#     def map_available_images(self):\n",
    "#         \"\"\"Find all available images in nested directory structure\"\"\"\n",
    "#         print(\"Mapping available images...\")\n",
    "#         self.available_images = {}\n",
    "        \n",
    "#         # Recursively walk through all subdirectories\n",
    "#         for root, _, files in tqdm(os.walk(self.base_image_dir)):\n",
    "#             for file in files:\n",
    "#                 if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "#                     article_id = Path(file).stem\n",
    "#                     full_path = Path(root) / file\n",
    "#                     self.available_images[article_id] = full_path\n",
    "        \n",
    "#         print(f\"Found {len(self.available_images)} images\")\n",
    "    \n",
    "#     def preprocess_image(self, image_path):\n",
    "#         \"\"\"Preprocess image exactly as done in the original CNN model\"\"\"\n",
    "#         try:\n",
    "#             img = Image.open(image_path)\n",
    "#             img = img.convert('RGB')  \n",
    "#             img = img.resize((180, 180))  \n",
    "#             img_array = img_to_array(img)\n",
    "#             img_array = img_array / 255.0  \n",
    "#             img_array = np.expand_dims(img_array, axis=0)\n",
    "#             return img_array\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing image {image_path}: {e}\")\n",
    "#             return None\n",
    "    \n",
    "#     def process_database_images(self, batch_size=32, force_reprocess=False):\n",
    "#         \"\"\"\n",
    "#         Process all available images and cache their features\n",
    "        \n",
    "#         Args:\n",
    "#             batch_size: Number of images to process at once\n",
    "#             force_reprocess: If True, reprocess all images even if cached\n",
    "#         \"\"\"\n",
    "#         print(\"Loading/extracting features from database images...\")\n",
    "#         self.image_features = {}\n",
    "        \n",
    "#         cached_count = 0\n",
    "#         if not force_reprocess:\n",
    "#             for article_id in tqdm(self.available_images.keys(), desc=\"Loading cached features\"):\n",
    "#                 feature_path = self.cache_dir / f\"{article_id}_features.npz\"\n",
    "#                 if feature_path.exists():\n",
    "#                     try:\n",
    "#                         with np.load(feature_path, allow_pickle=True) as data:\n",
    "#                             self.image_features[article_id] = {\n",
    "#                                 'classifications': data['classifications'].item(),\n",
    "#                                 'embeddings': data['embeddings']\n",
    "#                             }\n",
    "#                             cached_count += 1\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error loading cached features for {article_id}: {e}\")\n",
    "        \n",
    "#         print(f\"Loaded {cached_count} cached features\")\n",
    "        \n",
    "#         remaining_ids = [aid for aid in self.available_images.keys() \n",
    "#                         if aid not in self.image_features or force_reprocess]\n",
    "        \n",
    "#         if remaining_ids:\n",
    "#             print(f\"Processing {len(remaining_ids)} new images...\")\n",
    "#             for i in tqdm(range(0, len(remaining_ids), batch_size), desc=\"Processing new images\"):\n",
    "#                 batch_ids = remaining_ids[i:i + batch_size]\n",
    "#                 batch_images = []\n",
    "#                 valid_ids = []\n",
    "                \n",
    "#                 for article_id in batch_ids:\n",
    "#                     img_array = self.preprocess_image(self.available_images[article_id])\n",
    "#                     if img_array is not None:\n",
    "#                         batch_images.append(img_array[0])\n",
    "#                         valid_ids.append(article_id)\n",
    "                \n",
    "#                 if batch_images:\n",
    "#                     batch_array = np.array(batch_images)\n",
    "#                     features = self.extract_features(batch_array)\n",
    "                    \n",
    "#                     for idx, article_id in enumerate(valid_ids):\n",
    "#                         image_features = {\n",
    "#                             'classifications': {\n",
    "#                                 name: pred[idx] for name, pred in features['classifications'].items()\n",
    "#                             },\n",
    "#                             'embeddings': features['embeddings'][idx]\n",
    "#                         }\n",
    "                        \n",
    "#                         self.image_features[article_id] = image_features\n",
    "                        \n",
    "#                         # Save to cache immediately after processing each batch\n",
    "#                         np.savez(\n",
    "#                             self.cache_dir / f\"{article_id}_features.npz\",\n",
    "#                             classifications=image_features['classifications'],\n",
    "#                             embeddings=image_features['embeddings']\n",
    "#                         )\n",
    "                        \n",
    "#                         self.cache_metadata['processed_images'][article_id] = {\n",
    "#                             'last_processed': datetime.now().isoformat(),\n",
    "#                             'feature_shapes': {\n",
    "#                                 'classifications': {\n",
    "#                                     name: preds.shape if hasattr(preds, 'shape') else None\n",
    "#                                     for name, preds in image_features['classifications'].items()\n",
    "#                                 },\n",
    "#                                 'embeddings': image_features['embeddings'].shape\n",
    "#                             }\n",
    "#                         }\n",
    "                        \n",
    "#                 # Save metadata after each batch\n",
    "#                 self.save_cache_metadata()\n",
    "        \n",
    "#         self.cache_metadata['last_update'] = datetime.now().isoformat()\n",
    "#         self.save_cache_metadata()\n",
    "        \n",
    "#         print(f\"Total processed features: {len(self.image_features)}\")\n",
    "#     def find_similar_images(self, query_features, top_k=5):\n",
    "#         \"\"\"\n",
    "#         Find similar images based on both embeddings and classifications.\n",
    "#         Fixed to properly handle array operations and similarity calculations.\n",
    "        \n",
    "#         Args:\n",
    "#             query_features: Dictionary containing 'classifications' and 'embeddings'\n",
    "#             top_k: Number of top matches to return\n",
    "#         Returns:\n",
    "#             List of dictionaries containing match information\n",
    "#         \"\"\"\n",
    "#         similarities = {}\n",
    "#         query_embedding = query_features['embeddings'].flatten()\n",
    "#         query_classifications = query_features['classifications']\n",
    "        \n",
    "#         for article_id, features in self.image_features.items():\n",
    "#             # Calculate embedding similarity using cosine similarity\n",
    "#             db_embedding = features['embeddings'].flatten()\n",
    "#             embedding_similarity = float(\n",
    "#                 np.dot(query_embedding, db_embedding) / (\n",
    "#                     np.linalg.norm(query_embedding) * np.linalg.norm(db_embedding)\n",
    "#                 )\n",
    "#             )\n",
    "            \n",
    "#             # Calculate classification similarity\n",
    "#             classification_similarity = 0.0\n",
    "#             total_classes = 0\n",
    "#             for name in query_classifications.keys():\n",
    "#                 if name in features['classifications']:\n",
    "#                     # Handle multi-class predictions properly\n",
    "#                     query_pred = query_classifications[name]\n",
    "#                     db_pred = features['classifications'][name]\n",
    "                    \n",
    "#                     # Ensure we're working with flattened arrays\n",
    "#                     query_pred = np.array(query_pred).flatten()\n",
    "#                     db_pred = np.array(db_pred).flatten()\n",
    "                    \n",
    "#                     # Calculate cosine similarity for this classification\n",
    "#                     if np.any(query_pred) and np.any(db_pred):  # Avoid zero vectors\n",
    "#                         sim = float(\n",
    "#                             np.dot(query_pred, db_pred) / (\n",
    "#                                 np.linalg.norm(query_pred) * np.linalg.norm(db_pred)\n",
    "#                             )\n",
    "#                         )\n",
    "#                         classification_similarity += sim\n",
    "#                         total_classes += 1\n",
    "            \n",
    "#             # Normalize classification similarity\n",
    "#             if total_classes > 0:\n",
    "#                 classification_similarity /= total_classes\n",
    "            \n",
    "#             # Combine similarities with weighted average\n",
    "#             # Adjust these weights based on which feature type is more important\n",
    "#             similarity = (0.6 * embedding_similarity + 0.4 * classification_similarity)\n",
    "#             similarities[article_id] = float(similarity)\n",
    "    \n",
    "#         # Get top k matches\n",
    "#         similar_items = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "#         return [\n",
    "#             {\n",
    "#                 'article_id': article_id,\n",
    "#                 'similarity_score': float(similarity),\n",
    "#                 'image_path': str(self.available_images[article_id]),\n",
    "#                 'features': self.image_features[article_id],\n",
    "#                 'embedding_sim': float(embedding_similarity),  # Added for debugging\n",
    "#                 'classification_sim': float(classification_similarity)  # Added for debugging\n",
    "#             }\n",
    "#             for article_id, similarity in similar_items\n",
    "#         ]\n",
    "    \n",
    "#     def visualize_matches(self, original_features, matches, title=\"Matching Results\"):\n",
    "#         \"\"\"\n",
    "#         Enhanced visualization method with more detailed similarity information\n",
    "#         \"\"\"\n",
    "#         n_matches = len(matches)\n",
    "#         fig = plt.figure(figsize=(15, 6))\n",
    "        \n",
    "#         # Plot original features using embeddings\n",
    "#         plt.subplot(1, n_matches + 1, 1)\n",
    "#         embedding_array = original_features['embeddings'].flatten()\n",
    "#         square_size = int(np.sqrt(len(embedding_array)))\n",
    "#         display_array = embedding_array[:square_size * square_size].reshape((square_size, -1))\n",
    "#         plt.imshow(display_array, cmap='viridis')\n",
    "#         plt.title(\"Query\\nImage\")\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         # Plot matching images\n",
    "#         for idx, match in enumerate(matches):\n",
    "#             plt.subplot(1, n_matches + 1, idx + 2)\n",
    "#             try:\n",
    "#                 img = Image.open(match['image_path'])\n",
    "#                 plt.imshow(img)\n",
    "#                 # Show both embedding and classification similarities\n",
    "#                 plt.title(f\"Match {idx + 1}\\nTotal: {match['similarity_score']:.2f}\\n\"\n",
    "#                          f\"Emb: {match.get('embedding_sim', 0):.2f}\\n\"\n",
    "#                          f\"Class: {match.get('classification_sim', 0):.2f}\")\n",
    "#             except Exception as e:\n",
    "#                 plt.text(0.5, 0.5, f\"Error loading image:\\n{str(e)}\", \n",
    "#                         ha='center', va='center')\n",
    "#             plt.axis('off')\n",
    "        \n",
    "#         plt.suptitle(title)\n",
    "#         plt.tight_layout()\n",
    "#         return fig\n",
    "        \n",
    "#         def match_outfit_recommendations(self, recommendations, top_k=5, visualize=True):\n",
    "#             \"\"\"\n",
    "#             Match each recommended feature vector to similar images\n",
    "            \n",
    "#             Args:\n",
    "#                 recommendations: Dictionary of category-feature pairs from your CNN model\n",
    "#                 top_k: Number of matches to return per item\n",
    "#                 visualize: If True, create visualization plots\n",
    "            \n",
    "#             Returns:\n",
    "#                 Dictionary mapping categories to lists of similar images and optional plots\n",
    "#             \"\"\"\n",
    "#             matched_outfit = {}\n",
    "#             visualizations = {}\n",
    "            \n",
    "#             for category, features in recommendations.items():\n",
    "#                 similar_images = self.find_similar_images(features, top_k=top_k)\n",
    "#                 matched_outfit[category] = similar_images\n",
    "                \n",
    "#                 if visualize:\n",
    "#                     fig = self.visualize_matches(\n",
    "#                         features,\n",
    "#                         similar_images,\n",
    "#                         title=f\"Matches for {category}\"\n",
    "#                     )\n",
    "#                     visualizations[category] = fig\n",
    "            \n",
    "#             return matched_outfit, visualizations if visualize else matched_outfit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49157bd8-5fba-4def-8e6d-442b26bd29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def setup_matcher(classification_model_path, image_dir):\n",
    "#     \"\"\"Helper function to create and initialize the matching system\"\"\"\n",
    "#     print(\"Loading models and components...\")\n",
    "#     classification_model, label_binarizers, num_classes_dict = load_fashion_model(classification_model_path)\n",
    "#     embedding_model = create_embedding_model(classification_model)\n",
    "    \n",
    "#     print(\"Initializing matcher...\")\n",
    "#     matcher = EnhancedImageMatcher(\n",
    "#         classification_model=classification_model,\n",
    "#         embedding_model=embedding_model,\n",
    "#         label_binarizers=label_binarizers,\n",
    "#         base_image_dir=image_dir\n",
    "#     )\n",
    "    \n",
    "#     print(\"Processing database images...\")\n",
    "#     matcher.process_database_images()\n",
    "    \n",
    "#     return matcher, classification_model, embedding_model, label_binarizers\n",
    "\n",
    "# matcher, classification_model, embedding_model, label_binarizers = setup_matcher(\n",
    "#     classification_model_path='fashion_model',\n",
    "#     image_dir=\"images1\"\n",
    "# )\n",
    "\n",
    "# input_image_path = \"images/28865.jpg\"\n",
    "# input_array = matcher.preprocess_image(input_image_path)\n",
    "# input_features = matcher.extract_features(input_array)\n",
    "\n",
    "# matched_items = matcher.find_similar_images(\n",
    "#     input_features,\n",
    "#     top_k=5\n",
    "# )\n",
    "\n",
    "# matcher.visualize_matches(input_features, matched_items, \"Similar Items\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3bef6-fb5f-45af-a499-d507124dbdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matcher, classification_model, embedding_model, label_binarizers = setup_matcher(\n",
    "#     classification_model_path='fashion_model',\n",
    "#     image_dir=\"images1\"\n",
    "# )\n",
    "\n",
    "# input_image_path = \"images/28863.jpg\"\n",
    "# input_array = matcher.preprocess_image(input_image_path)\n",
    "# input_features = matcher.extract_features(input_array)\n",
    "\n",
    "# matched_items = matcher.find_similar_images(\n",
    "#     input_features,\n",
    "#     top_k=5\n",
    "# )\n",
    "\n",
    "# matcher.visualize_matches(input_features, matched_items, \"Similar Items\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af86c1-20c4-4741-8de3-21d498356240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# try:\n",
    "#     classification_model = load_model('classification_model')  \n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading model: {e}\")\n",
    "#     raise\n",
    "\n",
    "# matcher = setup_matcher(\n",
    "#     cnn_model=classification_model,\n",
    "#     image_dir=\"images1\"\n",
    "# )\n",
    "\n",
    "# recommendations = {\n",
    "#     'tops': top_features,      \n",
    "#     'bottoms': bottom_features,  \n",
    "#     'shoes': shoe_features      \n",
    "# }\n",
    "\n",
    "# # Get matches and visualizations\n",
    "# matched_outfit, visualizations = matcher.match_outfit_recommendations(\n",
    "#     recommendations,\n",
    "#     top_k=5,\n",
    "#     visualize=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f13e5-efdc-4843-80ea-d789cd592be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ClusteredImageMatcher:\n",
    "#     def __init__(self, classification_model, embedding_model, label_binarizers, base_image_dir, cache_dir='./features_cache'):\n",
    "#         self.base_image_dir = Path(base_image_dir)\n",
    "#         self.cache_dir = Path(cache_dir)\n",
    "#         self.cache_dir.mkdir(exist_ok=True)\n",
    "#         self.classification_model = classification_model\n",
    "#         self.embedding_model = embedding_model\n",
    "#         self.label_binarizers = label_binarizers\n",
    "#         self.cache_metadata_path = self.cache_dir / 'cache_metadata.json'\n",
    "#         self.category_index_path = self.cache_dir / 'category_index.json'\n",
    "#         self.image_features = {}\n",
    "#         self.category_index = {}\n",
    "#         self.loaded_categories = set()\n",
    "#         self.load_cache_metadata()\n",
    "#         self.create_or_load_category_index()\n",
    "        \n",
    "#     def create_or_load_category_index(self):\n",
    "#         \"\"\"Create or load category index mapping images to their categories\"\"\"\n",
    "#         if self.category_index_path.exists():\n",
    "#             with open(self.category_index_path, 'r') as f:\n",
    "#                 self.category_index = json.load(f)\n",
    "#             print(f\"Loaded category index with {len(self.category_index)} entries\")\n",
    "#         else:\n",
    "#             print(\"Creating new category index...\")\n",
    "#             self._create_category_index()\n",
    "    \n",
    "#     def _create_category_index(self):\n",
    "#         \"\"\"Create category index by processing all images once\"\"\"\n",
    "#         self.category_index = {}\n",
    "#         batch_size = 32\n",
    "#         all_images = list(Path(self.base_image_dir).rglob('*.[jJ][pP][gG]'))\n",
    "        \n",
    "#         for i in tqdm(range(0, len(all_images), batch_size), desc=\"Creating category index\"):\n",
    "#             batch_paths = all_images[i:i + batch_size]\n",
    "#             batch_arrays = []\n",
    "#             valid_paths = []\n",
    "            \n",
    "#             for path in batch_paths:\n",
    "#                 img_array = self.preprocess_image(path)\n",
    "#                 if img_array is not None:\n",
    "#                     batch_arrays.append(img_array[0])\n",
    "#                     valid_paths.append(path)\n",
    "            \n",
    "#             if batch_arrays:\n",
    "#                 batch_array = np.array(batch_arrays)\n",
    "#                 features = self.classification_model.predict(batch_array)\n",
    "                \n",
    "#                 for idx, path in enumerate(valid_paths):\n",
    "#                     article_id = path.stem\n",
    "#                     categories = self._get_categories_from_predictions(features[idx])\n",
    "#                     self.category_index[article_id] = {\n",
    "#                         'path': str(path),\n",
    "#                         'categories': categories\n",
    "#                     }\n",
    "        \n",
    "#         with open(self.category_index_path, 'w') as f:\n",
    "#             json.dump(self.category_index, f)\n",
    "        \n",
    "#         print(f\"Created category index with {len(self.category_index)} entries\")\n",
    "    \n",
    "#     def _get_categories_from_predictions(self, predictions):\n",
    "#         \"\"\"Extract categories from model predictions\"\"\"\n",
    "#         categories = []\n",
    "#         threshold = 0.5  \n",
    "#         if isinstance(predictions, np.ndarray):\n",
    "#             categories = [\n",
    "#                 cat for idx, cat in enumerate(['mens', 'womens', 'children', \n",
    "#                 'shirts', 'pants', 'shoes', 'accessories'])\n",
    "#                 if predictions[idx] > threshold\n",
    "#             ]\n",
    "        \n",
    "#         return categories\n",
    "    \n",
    "#     def _get_relevant_categories(self, query_features):\n",
    "#         \"\"\"Determine relevant categories for a query image\"\"\"\n",
    "#         query_categories = self._get_categories_from_predictions(\n",
    "#             query_features['classifications']\n",
    "#         )\n",
    "        \n",
    "#         category_relations = {\n",
    "#             'mens_shirts': ['mens_pants', 'mens_shoes', 'mens_accessories'],\n",
    "#             'mens_pants': ['mens_shirts', 'mens_shoes', 'mens_accessories'],\n",
    "#             'womens_shirts': ['womens_pants', 'womens_shoes', 'womens_accessories'],\n",
    "#         }\n",
    "        \n",
    "#         relevant_categories = set()\n",
    "#         for cat in query_categories:\n",
    "#             relevant_categories.add(cat)\n",
    "#             if cat in category_relations:\n",
    "#                 relevant_categories.update(category_relations[cat])\n",
    "        \n",
    "#         return list(relevant_categories)\n",
    "    \n",
    "#     def load_category_features(self, categories):\n",
    "#         \"\"\"Load features only for specified categories\"\"\"\n",
    "#         new_categories = set(categories) - self.loaded_categories\n",
    "        \n",
    "#         if not new_categories:\n",
    "#             return  \n",
    "        \n",
    "#         print(f\"Loading features for categories: {new_categories}\")\n",
    "        \n",
    "#         relevant_ids = [\n",
    "#             article_id for article_id, info in self.category_index.items()\n",
    "#             if any(cat in info['categories'] for cat in new_categories)\n",
    "#         ]\n",
    "        \n",
    "#         for article_id in tqdm(relevant_ids, desc=\"Loading category features\"):\n",
    "#             feature_path = self.cache_dir / f\"{article_id}_features.npz\"\n",
    "#             if feature_path.exists():\n",
    "#                 with np.load(feature_path, allow_pickle=True) as data:\n",
    "#                     self.image_features[article_id] = {\n",
    "#                         'classifications': data['classifications'].item(),\n",
    "#                         'embeddings': data['embeddings']\n",
    "#                     }\n",
    "        \n",
    "#         self.loaded_categories.update(new_categories)\n",
    "#         print(f\"Loaded {len(relevant_ids)} new images\")\n",
    "    \n",
    "#     def find_similar_images(self, query_features, top_k=5):\n",
    "#         \"\"\"Find similar images, loading only relevant categories\"\"\"\n",
    "#         relevant_categories = self._get_relevant_categories(query_features)\n",
    "#         self.load_category_features(relevant_categories)\n",
    "        \n",
    "#         similarities = {}\n",
    "#         query_embedding = query_features['embeddings'].flatten()\n",
    "#         query_classifications = query_features['classifications']\n",
    "        \n",
    "#         similarity_components = {}\n",
    "        \n",
    "#         for article_id, features in self.image_features.items():\n",
    "#             db_embedding = features['embeddings'].flatten()\n",
    "#             embedding_similarity = float(\n",
    "#                 np.dot(query_embedding, db_embedding) / (\n",
    "#                     np.linalg.norm(query_embedding) * np.linalg.norm(db_embedding)\n",
    "#                 )\n",
    "#             )\n",
    "            \n",
    "#             classification_similarity = 0.0\n",
    "#             total_classes = 0\n",
    "#             for name in query_classifications.keys():\n",
    "#                 if name in features['classifications']:\n",
    "#                     query_pred = query_classifications[name]\n",
    "#                     db_pred = features['classifications'][name]\n",
    "                    \n",
    "#                     query_pred = np.array(query_pred).flatten()\n",
    "#                     db_pred = np.array(db_pred).flatten()\n",
    "                    \n",
    "#                     if np.any(query_pred) and np.any(db_pred):\n",
    "#                         sim = float(\n",
    "#                             np.dot(query_pred, db_pred) / (\n",
    "#                                 np.linalg.norm(query_pred) * np.linalg.norm(db_pred)\n",
    "#                             )\n",
    "#                         )\n",
    "#                         classification_similarity += sim\n",
    "#                         total_classes += 1\n",
    "            \n",
    "#             if total_classes > 0:\n",
    "#                 classification_similarity /= total_classes\n",
    "            \n",
    "#             similarity = (0.6 * embedding_similarity + 0.4 * classification_similarity)\n",
    "#             similarities[article_id] = float(similarity)\n",
    "            \n",
    "#             similarity_components[article_id] = {\n",
    "#                 'embedding_sim': float(embedding_similarity),\n",
    "#                 'classification_sim': float(classification_similarity)\n",
    "#             }\n",
    "        \n",
    "#         similar_items = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "#         results = []\n",
    "#         for article_id, similarity in similar_items:\n",
    "#             result = {\n",
    "#                 'article_id': article_id,\n",
    "#                 'similarity_score': float(similarity),\n",
    "#                 'image_path': str(self.category_index[article_id]['path']),\n",
    "#                 'features': self.image_features[article_id],\n",
    "#                 'embedding_sim': similarity_components[article_id]['embedding_sim'],\n",
    "#                 'classification_sim': similarity_components[article_id]['classification_sim'],\n",
    "#                 'categories': self.category_index[article_id]['categories']\n",
    "#             }\n",
    "#             results.append(result)\n",
    "        \n",
    "#         return results\n",
    "\n",
    "#     def get_recommendations(self, input_image_path, top_k=5):\n",
    "#         \"\"\"\n",
    "#         Convenience method for getting recommendations\n",
    "        \n",
    "#         Args:\n",
    "#             input_image_path: Path to the query image\n",
    "#             top_k: Number of recommendations to return\n",
    "#         Returns:\n",
    "#             List of similar items with detailed similarity information\n",
    "#         \"\"\"\n",
    "#         input_array = self.preprocess_image(input_image_path)\n",
    "#         if input_array is None:\n",
    "#             raise ValueError(\"Could not process input image\")\n",
    "            \n",
    "#         input_features = self.extract_features(input_array)\n",
    "        \n",
    "#         matches = self.find_similar_images(input_features, top_k=top_k)\n",
    "        \n",
    "#         return matches\n",
    "\n",
    "#     def visualize_recommendations(self, query_image_path, recommendations, title=\"Recommendation Results\"):\n",
    "#         \"\"\"\n",
    "#         Visualize recommendations with detailed similarity information\n",
    "        \n",
    "#         Args:\n",
    "#             query_image_path: Path to the query image\n",
    "#             recommendations: List of recommendation results\n",
    "#             title: Title for the visualization\n",
    "#         \"\"\"\n",
    "#         n_matches = len(recommendations)\n",
    "#         fig = plt.figure(figsize=(15, 8))\n",
    "        \n",
    "#         plt.subplot(2, n_matches + 1, 1)\n",
    "#         query_img = Image.open(query_image_path)\n",
    "#         plt.imshow(query_img)\n",
    "#         plt.title(\"Query Image\")\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(2, n_matches + 1, n_matches + 2)\n",
    "#         plt.text(0.5, 0.5, \"Query Categories:\\n\" + \n",
    "#                 \"\\n\".join(self._get_relevant_categories({'classifications': None})),\n",
    "#                 ha='center', va='center')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         for idx, match in enumerate(recommendations):\n",
    "#             plt.subplot(2, n_matches + 1, idx + 2)\n",
    "#             try:\n",
    "#                 img = Image.open(match['image_path'])\n",
    "#                 plt.imshow(img)\n",
    "#                 plt.title(f\"Match {idx + 1}\\nScore: {match['similarity_score']:.2f}\")\n",
    "#             except Exception as e:\n",
    "#                 plt.text(0.5, 0.5, f\"Error loading image:\\n{str(e)}\", \n",
    "#                         ha='center', va='center')\n",
    "#             plt.axis('off')\n",
    "            \n",
    "#             # Details\n",
    "#             plt.subplot(2, n_matches + 1, n_matches + idx + 3)\n",
    "#             details = (f\"Emb: {match['embedding_sim']:.2f}\\n\"\n",
    "#                       f\"Class: {match['classification_sim']:.2f}\\n\"\n",
    "#                       f\"Categories: {', '.join(match['categories'])}\")\n",
    "#             plt.text(0.5, 0.5, details, ha='center', va='center')\n",
    "#             plt.axis('off')\n",
    "        \n",
    "#         plt.suptitle(title)\n",
    "#         plt.tight_layout()\n",
    "#         return fig\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e22d1-b8c9-4cdb-b69b-22b41fbcf883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f59eaa-afc6-4e3d-8388-e9e930c69875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1197b-1227-4e5a-bc77-de43ef6ef423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MetadataGeneratorMatcher:\n",
    "#     def __init__(self, classification_model, embedding_model, label_binarizers, base_image_dir, cache_dir='./features_cache'):\n",
    "#         self.base_image_dir = Path(base_image_dir)\n",
    "#         self.cache_dir = Path(cache_dir)\n",
    "#         self.cache_dir.mkdir(exist_ok=True)\n",
    "#         self.classification_model = classification_model\n",
    "#         self.embedding_model = embedding_model\n",
    "#         self.label_binarizers = label_binarizers\n",
    "#         self.metadata_path = self.cache_dir / 'generated_metadata.json'\n",
    "#         self.category_stats_path = self.cache_dir / 'category_statistics.json'\n",
    "#         self.metadata = {}\n",
    "#         self.category_stats = {}\n",
    "#         self.image_features = {}\n",
    "        \n",
    "#         self.generate_or_load_metadata()\n",
    "        \n",
    "#     def generate_or_load_metadata(self):\n",
    "#         \"\"\"Generate metadata for all images or load from cache\"\"\"\n",
    "#         if self.metadata_path.exists():\n",
    "#             print(\"Loading existing metadata...\")\n",
    "#             with open(self.metadata_path, 'r') as f:\n",
    "#                 self.metadata = json.load(f)\n",
    "#             with open(self.category_stats_p\n",
    "\n",
    "\n",
    "ath, 'r') as f:\n",
    "#                 self.category_stats = json.load(f)\n",
    "#             print(f\"Loaded metadata for {len(self.metadata)} images\")\n",
    "#             self._print_category_statistics()\n",
    "#         else:\n",
    "#             print(\"Generating new metadata for all images...\")\n",
    "#             self._generate_metadata()\n",
    "    \n",
    "#     def _generate_metadata(self):\n",
    "#         \"\"\"Process all images to generate metadata and category statistics\"\"\"\n",
    "#         batch_size = 32\n",
    "#         all_images = list(Path(self.base_image_dir).rglob('*.[jJ][pP][gG]'))\n",
    "#         total_images = len(all_images)\n",
    "        \n",
    "#         self.category_stats = {\n",
    "#             'total_images': total_images,\n",
    "#             'categories': {},\n",
    "#             'category_combinations': {}\n",
    "#         }\n",
    "        \n",
    "#         print(f\"Processing {total_images} images...\")\n",
    "        \n",
    "#         for i in tqdm(range(0, total_images, batch_size), desc=\"Generating metadata\"):\n",
    "#             batch_paths = all_images[i:i + batch_size]\n",
    "#             batch_arrays = []\n",
    "#             valid_paths = []\n",
    "            \n",
    "#             for path in batch_paths:\n",
    "#                 img_array = self.preprocess_image(path)\n",
    "#                 if img_array is not None:\n",
    "#                     batch_arrays.append(img_array[0])\n",
    "#                     valid_paths.append(path)\n",
    "            \n",
    "#             if batch_arrays:\n",
    "#                 batch_array = np.array(batch_arrays)\n",
    "#                 classifications = self.classification_model.predict(batch_array)\n",
    "#                 embeddings = self.embedding_model.predict(batch_array)\n",
    "                \n",
    "#                 for idx, path in enumerate(valid_paths):\n",
    "#                     article_id = path.stem\n",
    "                    \n",
    "#                     categories = self._process_predictions(classifications[idx])\n",
    "                    \n",
    "#                     self.metadata[article_id] = {\n",
    "#                         'path': str(path),\n",
    "#                         'categories': categories['categories'],\n",
    "#                         'confidence_scores': categories['scores'],\n",
    "#                         'primary_category': categories['primary_category']\n",
    "#                     }\n",
    "                    \n",
    "#                     self._update_category_stats(categories['categories'])\n",
    "                    \n",
    "#                     feature_path = self.cache_dir / f\"{article_id}_features.npz\"\n",
    "#                     np.savez(\n",
    "#                         feature_path,\n",
    "#                         classifications=classifications[idx],\n",
    "#                         embeddings=embeddings[idx]\n",
    "#                     )\n",
    "        \n",
    "#         total = self.category_stats['total_images']\n",
    "#         for cat, count in self.category_stats['categories'].items():\n",
    "#             self.category_stats['categories'][cat] = {\n",
    "#                 'count': count,\n",
    "#                 'percentage': (count / total) * 100\n",
    "#             }\n",
    "        \n",
    "#         with open(self.metadata_path, 'w') as f:\n",
    "#             json.dump(self.metadata, f)\n",
    "#         with open(self.category_stats_path, 'w') as f:\n",
    "#             json.dump(self.category_stats, f)\n",
    "        \n",
    "#         self._print_category_statistics()\n",
    "    \n",
    "#     def _process_predictions(self, predictions):\n",
    "#         \"\"\"Process model predictions into categories with confidence scores\"\"\"\n",
    "#         threshold = 0.3  \n",
    "#         categories = []\n",
    "#         scores = {}\n",
    "        \n",
    "#         category_names = ['mens', 'womens', 'children', 'shirts', 'pants', 'shoes', 'accessories']\n",
    "#         for idx, score in enumerate(predictions):\n",
    "#             if score > threshold:\n",
    "#                 cat = category_names[idx]\n",
    "#                 categories.append(cat)\n",
    "#                 scores[cat] = float(score)\n",
    "        \n",
    "#         primary_category = max(scores.items(), key=lambda x: x[1])[0] if scores else None\n",
    "        \n",
    "#         return {\n",
    "#             'categories': categories,\n",
    "#             'scores': scores,\n",
    "#             'primary_category': primary_category\n",
    "#         }\n",
    "    \n",
    "#     def _update_category_stats(self, categories):\n",
    "#         \"\"\"Update category statistics\"\"\"\n",
    "#         for cat in categories:\n",
    "#             if cat not in self.category_stats['categories']:\n",
    "#                 self.category_stats['categories'][cat] = 0\n",
    "#             self.category_stats['categories'][cat] += 1\n",
    "        \n",
    "#         combo = '+'.join(sorted(categories))\n",
    "#         if combo not in self.category_stats['category_combinations']:\n",
    "#             self.category_stats['category_combinations'][combo] = 0\n",
    "#         self.category_stats['category_combinations'][combo] += 1\n",
    "    \n",
    "#     def _print_category_statistics(self):\n",
    "#         \"\"\"Print category distribution statistics\"\"\"\n",
    "#         print(\"\\nCategory Distribution:\")\n",
    "#         for cat, stats in self.category_stats['categories'].items():\n",
    "#             print(f\"{cat}: {stats['count']} images ({stats['percentage']:.1f}%)\")\n",
    "        \n",
    "#         print(\"\\nTop Category Combinations:\")\n",
    "#         combinations = sorted(\n",
    "#             self.category_stats['category_combinations'].items(),\n",
    "#             key=lambda x: x[1],\n",
    "#             reverse=True\n",
    "#         )[:10]\n",
    "#         for combo, count in combinations:\n",
    "#             print(f\"{combo}: {count} images\")\n",
    "    \n",
    "#     def load_category_features(self, categories, limit=1000):\n",
    "#         \"\"\"Load features for specified categories with limit\"\"\"\n",
    "#         relevant_ids = [\n",
    "#             article_id for article_id, info in self.metadata.items()\n",
    "#             if any(cat in info['categories'] for cat in categories)\n",
    "#         ]\n",
    "        \n",
    "#         relevant_ids = sorted(\n",
    "#             relevant_ids,\n",
    "#             key=lambda x: max(self.metadata[x]['confidence_scores'].values()),\n",
    "#             reverse=True\n",
    "#         )[:limit]\n",
    "        \n",
    "#         print(f\"Loading {len(relevant_ids)} features for categories: {categories}\")\n",
    "        \n",
    "#         for article_id in tqdm(relevant_ids, desc=\"Loading features\"):\n",
    "#             feature_path = self.cache_dir / f\"{article_id}_features.npz\"\n",
    "#             if feature_path.exists():\n",
    "#                 with np.load(feature_path, allow_pickle=True) as data:\n",
    "#                     self.image_features[article_id] = {\n",
    "#                         'classifications': data['classifications'],\n",
    "#                         'embeddings': data['embeddings']\n",
    "#                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52a271-bc3d-40ba-b11a-8450b240afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matcher = ClusteredImageMatcher(\n",
    "#     classification_model=classification_model,\n",
    "#     embedding_model=embedding_model,\n",
    "#     label_binarizers=label_binarizers,\n",
    "#     base_image_dir=\"images1\"\n",
    "# )\n",
    "\n",
    "# recommendations = matcher.get_recommendations(\n",
    "#     input_image_path=\"images/28865.jpg\",\n",
    "#     top_k=5\n",
    "# )\n",
    "\n",
    "# matcher.visualize_recommendations(\n",
    "#     query_image_path=\"images/28865.jpg\",\n",
    "#     recommendations=recommendations,\n",
    "#     title=\"Fashion Recommendations\"\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9be7c-e5a0-41a5-87bd-cc200a028b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
